{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    feature = data.drop(columns=['price', 'id', 'date', 'zipcode'])\n",
    "    \n",
    "    for c in feature.columns:\n",
    "        col = feature[c]\n",
    "        print(f'Column {c} summary:')\n",
    "        print(f'- maximum {np.amax(col)}')\n",
    "        print(f'- minimum {np.amin(col)}')\n",
    "        print(f'- average {np.average(col)}')\n",
    "        print(f'- variance {np.var(col)}')\n",
    "        print('\\n')\n",
    "    \n",
    "    corr = data.drop(columns=['id', 'date', 'zipcode']).corr()['price']\n",
    "    columns = sorted(feature.columns,key=lambda x: corr[x])\n",
    "    \n",
    "    for c in columns:\n",
    "        print(f'Correlation price vs. {c}: {corr[c]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column bedrooms summary:\n",
      "- maximum 33\n",
      "- minimum 0\n",
      "- average 3.37084162309721\n",
      "- variance 0.8649749868540167\n",
      "\n",
      "\n",
      "Column bathrooms summary:\n",
      "- maximum 8.0\n",
      "- minimum 0.0\n",
      "- average 2.1147573219821405\n",
      "- variance 0.5931238445451253\n",
      "\n",
      "\n",
      "Column sqft_living summary:\n",
      "- maximum 13540\n",
      "- minimum 290\n",
      "- average 2079.8997362698374\n",
      "- variance 843494.6523725765\n",
      "\n",
      "\n",
      "Column sqft_lot summary:\n",
      "- maximum 1651359\n",
      "- minimum 520\n",
      "- average 15106.967565816869\n",
      "- variance 1715579393.3040423\n",
      "\n",
      "\n",
      "Column floors summary:\n",
      "- maximum 3.5\n",
      "- minimum 1.0\n",
      "- average 1.4943089807060566\n",
      "- variance 0.2915745155520679\n",
      "\n",
      "\n",
      "Column waterfront summary:\n",
      "- maximum 1\n",
      "- minimum 0\n",
      "- average 0.007541757275713691\n",
      "- variance 0.007484879172907909\n",
      "\n",
      "\n",
      "Column view summary:\n",
      "- maximum 4\n",
      "- minimum 0\n",
      "- average 0.23430342849211122\n",
      "- variance 0.5872154461720236\n",
      "\n",
      "\n",
      "Column condition summary:\n",
      "- maximum 5\n",
      "- minimum 1\n",
      "- average 3.4094295100171195\n",
      "- variance 0.4234469192550091\n",
      "\n",
      "\n",
      "Column grade summary:\n",
      "- maximum 13\n",
      "- minimum 1\n",
      "- average 7.656873178179799\n",
      "- variance 1.3816393600787207\n",
      "\n",
      "\n",
      "Column sqft_above summary:\n",
      "- maximum 9410\n",
      "- minimum 290\n",
      "- average 1788.3906907879516\n",
      "- variance 685702.9393886543\n",
      "\n",
      "\n",
      "Column sqft_basement summary:\n",
      "- maximum 4820\n",
      "- minimum 0\n",
      "- average 291.5090454818859\n",
      "- variance 195863.60567628779\n",
      "\n",
      "\n",
      "Column yr_built summary:\n",
      "- maximum 2015\n",
      "- minimum 1900\n",
      "- average 1971.0051357978994\n",
      "- variance 862.7573418741698\n",
      "\n",
      "\n",
      "Column yr_renovated summary:\n",
      "- maximum 2015\n",
      "- minimum 0\n",
      "- average 84.40225790033776\n",
      "- variance 161338.74662332\n",
      "\n",
      "\n",
      "Column lat summary:\n",
      "- maximum 47.7776\n",
      "- minimum 47.1559\n",
      "- average 47.56005251931708\n",
      "- variance 0.019199013446320422\n",
      "\n",
      "\n",
      "Column long summary:\n",
      "- maximum -121.315\n",
      "- minimum -122.51899999999999\n",
      "- average -122.21389640494147\n",
      "- variance 0.019831704393220007\n",
      "\n",
      "\n",
      "Column sqft_living15 summary:\n",
      "- maximum 6210\n",
      "- minimum 399\n",
      "- average 1986.552491556008\n",
      "- variance 469739.50482109515\n",
      "\n",
      "\n",
      "Column sqft_lot15 summary:\n",
      "- maximum 871200\n",
      "- minimum 651\n",
      "- average 12768.455651691113\n",
      "- variance 745483731.3680073\n",
      "\n",
      "\n",
      "Correlation price vs. long: 0.02162624103930622\n",
      "Correlation price vs. condition: 0.03636178912899409\n",
      "Correlation price vs. yr_built: 0.05401153149478604\n",
      "Correlation price vs. sqft_lot15: 0.08244715251948594\n",
      "Correlation price vs. sqft_lot: 0.08966086058710003\n",
      "Correlation price vs. yr_renovated: 0.12643379344092243\n",
      "Correlation price vs. floors: 0.25679388755070176\n",
      "Correlation price vs. waterfront: 0.26636943403055346\n",
      "Correlation price vs. lat: 0.307003479995218\n",
      "Correlation price vs. bedrooms: 0.3083495981456364\n",
      "Correlation price vs. sqft_basement: 0.323816020712004\n",
      "Correlation price vs. view: 0.3972934882944871\n",
      "Correlation price vs. bathrooms: 0.5251375054139724\n",
      "Correlation price vs. sqft_living15: 0.5853789035795697\n",
      "Correlation price vs. sqft_above: 0.6055672983560842\n",
      "Correlation price vs. grade: 0.667434256020255\n",
      "Correlation price vs. sqft_living: 0.7020350546118009\n"
     ]
    }
   ],
   "source": [
    "analysis('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that all the feature are positively correllated to the housing price. Also, by sorting the feature columns, we can see that the `sqft_living` is highly correlated with the price of the house. Against to popular belief, the `condition` of the house doesn't correlate that much with the housing price, but the price does depend on the `grade` of the house.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y, scaled=False, dropped=['price', 'zipcode']):\n",
    "    x = x.drop(columns=dropped)\n",
    "    \n",
    "    if scaled:\n",
    "        # StandardScaler is sklearn's implementation for feature standardization\n",
    "        std_scaler = StandardScaler()\n",
    "        x = std_scaler.fit_transform(x)\n",
    "    else:\n",
    "        x = np.mat(x)\n",
    "    x[:,0] = 1   \n",
    "    \n",
    "    return x, np.mat(y).T\n",
    "\n",
    "def metrics(x, y, theta, rmse=False, r2=False):\n",
    "    y_pred = np.inner(theta.T, x).T\n",
    "    \n",
    "    mse = mean_squared_error(y_pred, y)\n",
    "    \n",
    "    print(f'MSE {mse}')\n",
    "    if rmse:\n",
    "        print(f'RSE {np.sqrt(mse)}')\n",
    "    \n",
    "    if r2:\n",
    "        r = r2_score(y_pred, y)\n",
    "        print(f'R2 score {r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Using pre-existing package on training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = preprocess(train, train['price'])\n",
    "x_test, y_test = preprocess(test, test['price'], dropped=['id', 'date', 'price', 'zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 1)\n"
     ]
    }
   ],
   "source": [
    "print(linreg.coef_.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 533128725123263.3\n",
      "RSE 23089580.444938\n",
      "R2 score -6372.249416053004\n"
     ]
    }
   ],
   "source": [
    "metrics(x_train, y_train, linreg.coef_.T, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 533331657178069.75\n",
      "RSE 23093974.477730542\n",
      "R2 score -5979.038879328858\n"
     ]
    }
   ],
   "source": [
    "metrics(x_test, y_test,linreg.coef_.T, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature standardization on training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_scaled, y_tr_scaled = preprocess(train, train['price'], scaled=True)\n",
    "x_t_scaled, y_t_scaled = preprocess(test, test['price'], scaled=True, dropped=['id', 'date', 'price', 'zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(x_tr_scaled, y_tr_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = linreg.coef_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 302317767223.0435\n",
      "RSE 549834.3088813607\n",
      "R2 score -2.6140362404426085\n"
     ]
    }
   ],
   "source": [
    "metrics(x_tr_scaled, y_tr_scaled, theta, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 352745793983.47125\n",
      "RSE 593924.0641559081\n",
      "R2 score -3.4979283746745846\n"
     ]
    }
   ],
   "source": [
    "metrics(x_t_scaled, y_t_scaled, theta, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Closed-form Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Simple linear regression on one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train['sqft_living'], train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = sum(x_train)/len(x_train)\n",
    "y_hat = sum(y_train)/len(y_train)\n",
    "\n",
    "theta_1 = sum([(x - x_hat)*(y - y_hat) for (x,y) in zip(x_train,y_train)]) / sum([(x - x_hat)**2 for x in x_train])\n",
    "theta_0 = y_hat - theta_1 * x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, theta):\n",
    "    return x * theta[1] + theta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 57947526161.28836\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = predict(x_train, [theta_0, theta_1])\n",
    "\n",
    "print(f'MSE {mean_squared_error(y_train_pred, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 88575978543.09607\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = test['sqft_living'], test['price']\n",
    "y_test_pred = predict(x_test, [theta_0, theta_1])\n",
    "\n",
    "print(f'MSE {mean_squared_error(y_test_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a huge gap between MSE from the test set and train set. Hence the model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    xT = x.T\n",
    "\n",
    "    theta = np.linalg.pinv(xT.dot(x)).dot(xT).dot(y_train)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, theta):\n",
    "    return theta.T.dot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 On unscaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = preprocess(train, train['price'])\n",
    "x_test, y_test = preprocess(test, test['price'], dropped=['id', 'date', 'price', 'zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = linear_regression(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 7.054089055862017e+16\n",
      "RSE 265595351.16153702\n",
      "R2 score -0.5456124873350419\n"
     ]
    }
   ],
   "source": [
    "metrics(x_train, y_train, theta, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 2.317305870407946e+17\n",
      "RSE 481384032.80623525\n",
      "R2 score -0.15223524616561668\n"
     ]
    }
   ],
   "source": [
    "metrics(x_test, y_test, theta, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 On scaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_scaled, y_tr_scaled = preprocess(train, train['price'], scaled=True)\n",
    "x_t_scaled, y_t_scaled = preprocess(test, test['price'], scaled=True, dropped=['id', 'date', 'price', 'zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = linear_regression(x_tr_scaled, y_tr_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 31486167775.794888\n",
      "RSE 177443.42133704165\n",
      "R2 score 0.6236008473480719\n"
     ]
    }
   ],
   "source": [
    "metrics(x_tr_scaled, y_tr_scaled, theta, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 59784365567.51628\n",
      "RSE 244508.41614863952\n",
      "R2 score 0.23767824072016086\n"
     ]
    }
   ],
   "source": [
    "metrics(x_t_scaled, y_t_scaled, theta, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, on scaled/standardized dataset, the MSE/RSE is fairly closed to the implementation from the one in sklearn. My own implementation of linear regression using the closed form has relatively bigger r2 score than sklearn's linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = preprocess(train, train['price'], scaled=True)\n",
    "x_test, y_test = preprocess(test, test['price'], scaled=True,dropped=['id', 'date', 'price', 'zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, n_iterations=100, eta=0.01):\n",
    "    m = y.shape[0]\n",
    "    theta = np.random.randn(x.shape[1], 1)\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        gradients = (2.0/m) * x.T.dot(x.dot(theta) - y)\n",
    "        theta = theta - eta * gradients\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001, 0.005, 0.01, 0.02, 0.03]\n",
    "n_iterations = [1000, 5000, 10000, 12000, 15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for learning rate 0.001 and number of iteration 1000:\n",
      "MSE 37005862810.976265\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.001 and number of iteration 5000:\n",
      "MSE 31498122026.934193\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.001 and number of iteration 10000:\n",
      "MSE 31486468894.5082\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.001 and number of iteration 12000:\n",
      "MSE 31486240814.380527\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.001 and number of iteration 15000:\n",
      "MSE 31486176993.93249\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.005 and number of iteration 1000:\n",
      "MSE 31498086832.77467\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.005 and number of iteration 5000:\n",
      "MSE 31486167788.7745\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.005 and number of iteration 10000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.005 and number of iteration 12000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.005 and number of iteration 15000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.01 and number of iteration 1000:\n",
      "MSE 31486465378.420647\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.01 and number of iteration 5000:\n",
      "MSE 31486167775.794888\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.01 and number of iteration 10000:\n",
      "MSE 31486167775.79489\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.01 and number of iteration 12000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.01 and number of iteration 15000:\n",
      "MSE 31486167775.79489\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.02 and number of iteration 1000:\n",
      "MSE 31486168093.073753\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.02 and number of iteration 5000:\n",
      "MSE 31486167775.79488\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.02 and number of iteration 10000:\n",
      "MSE 31486167775.79488\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.02 and number of iteration 12000:\n",
      "MSE 31486167775.794876\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.02 and number of iteration 15000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.03 and number of iteration 1000:\n",
      "MSE 31486167776.29721\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.03 and number of iteration 5000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.03 and number of iteration 10000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.03 and number of iteration 12000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n",
      "Metrics for learning rate 0.03 and number of iteration 15000:\n",
      "MSE 31486167775.794884\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for eta in learning_rate:\n",
    "    for it in n_iterations:\n",
    "        theta = gradient_descent(x_train, y_train, it, eta)\n",
    "        print(f'Metrics for learning rate {eta} and number of iteration {it}:')\n",
    "        metrics(x_train, y_train, theta)\n",
    "        print('------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient_descent implemented in here produce a lightly better MSE than the MSE from sklearn's Linear Regression (both used scaled package). From running metrics above, the MSE converge quite quickly after 5000 iterations no matter how big or small the learning rate. Let's test on the test set with theta from learning rate 0.01 and 5000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 59784364880.97162\n"
     ]
    }
   ],
   "source": [
    "theta = gradient_descent(x_train, y_train, n_iterations=5000, eta=0.01)\n",
    "metrics(x_test, y_test, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 On full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to run on kc_housing_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kc_house_data.csv')\n",
    "x, y = preprocess(data, data['price'], scaled=True, dropped=['id', 'price', 'date', 'zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = gradient_descent(x, y, n_iterations=5000, eta=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 41663212300.09703\n"
     ]
    }
   ],
   "source": [
    "metrics(x, y, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It run pretty fast, within a 1-2 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Ridge regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have ridge regression written as $$ J(\\theta) = \\frac{1}{2}\\sum_{i = 1}^n\\left(\\theta^T.x^{(i)} - y^{(i)}\\right)^2 + \\frac{1}{2}\\lambda\\sum_{i = 1}^{n}\\theta_i^2= MSE(\\theta) + \\frac{1}{2}\\lambda\\sum_{i = 1}^{n}\\theta_i^2$$\n",
    "We know from the lecture that\n",
    "$$\\frac{\\partial MSE}{\\partial \\theta} = X^T. (X. \\theta - y)$$\n",
    "and \n",
    "$$reg(\\theta) = \\frac{1}{2}\\lambda\\sum_{i = 1}^{n}\\theta_i^2 = \\frac{1}{2}\\lambda\\theta^2 \\Rightarrow \\frac{\\partial reg}{\\partial \\theta} = \\lambda \\theta$$\n",
    "Hence $J$ achieves minimum when \n",
    "$$X^T. (X. \\theta - y) + \\lambda \\theta = 0$$\n",
    "or \n",
    "$$(X^T.X + \\lambda I).\\theta = X^T.y$$\n",
    "or \n",
    "$$\\theta = (X^T.X + \\lambda I)^{-1}.X^T.y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(x, y, rate=0.005):\n",
    "    xT = x.T\n",
    "    A = np.identity(x.shape[1])\n",
    "    A[0][0] = 0\n",
    "    \n",
    "    theta = np.linalg.pinv(xT.dot(x) + rate * A).dot(xT).dot(y)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 31486167776.694233\n",
      "RSE 177443.4213395758\n",
      "R2 score 0.6235992591788334\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = preprocess(train, train['price'], scaled=True)\n",
    "x_test, y_test = preprocess(test, test['price'], scaled=True,dropped=['id', 'date', 'price', 'zipcode'])\n",
    "\n",
    "theta = ridge_regression(x_train, y_train)\n",
    "metrics(x_train, y_train, theta, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 59784427047.449394\n",
      "RSE 244508.54187011422\n",
      "R2 score 0.23767421302659986\n"
     ]
    }
   ],
   "source": [
    "metrics(x_test, y_test, theta, rmse=True, r2=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a relatively small dataset in train.csv and test.csv, both of the model (linear and ridge regression) are comparably produce the same result. However, for larger dataset, I would think ridge regression would be less overfitting since it adds an extra penalty for overfitting move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
