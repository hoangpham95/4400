{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/hoang/Documents/school/4400/env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "matrix = []\n",
    "\n",
    "with open(\"spambase.data\", \"r\") as raw_data:\n",
    "    for raw_line in raw_data:\n",
    "        line = [float(x) for x in raw_line.split(\",\")]\n",
    "        matrix.append(line)\n",
    "\n",
    "data = pd.DataFrame(matrix)\n",
    "row, col = data.shape\n",
    "X, y = data.iloc[:,:col - 1], data[col - 1]\n",
    "# y = y.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4 , 0.6 ],\n",
       "       [0.97, 0.03],\n",
       "       [0.96, 0.04],\n",
       "       ...,\n",
       "       [1.  , 0.  ],\n",
       "       [0.91, 0.09],\n",
       "       [0.58, 0.42]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfierData(clf):\n",
    "    test_data = clf.predict(X_test)\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(test_data, y_test), \"\\n\")\n",
    "    tn, fp, fn, tp = confusion_matrix(test_data, y_test).ravel()\n",
    "    print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "    print(\"Accuracy score\", accuracy_score(test_data, y_test), \"\\n\")\n",
    "    print(\"Precision\", precision_score(test_data, y_test), \"\\n\")\n",
    "    print(\"Recall\", recall_score(test_data, y_test), \"\\n\")\n",
    "    print(\"F1 score\", f1_score(test_data, y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[677  40]\n",
      " [ 20 414]] \n",
      "\n",
      "True negative: 677 , false positive: 40 , false negative: 20 ,true positive: 414 \n",
      "\n",
      "Accuracy score 0.947871416159861 \n",
      "\n",
      "Precision 0.9118942731277533 \n",
      "\n",
      "Recall 0.9539170506912442 \n",
      "\n",
      "F1 score 0.9324324324324325 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = clf.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(test_data, y_test), \"\\n\")\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_data, y_test).ravel()\n",
    "print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "\n",
    "print(\"Accuracy score\", accuracy_score(test_data, y_test), \"\\n\")\n",
    "\n",
    "print(\"Precision\", precision_score(test_data, y_test), \"\\n\")\n",
    "\n",
    "print(\"Recall\", recall_score(test_data, y_test), \"\\n\")\n",
    "\n",
    "print(\"F1 score\", f1_score(test_data, y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[2091    0]\n",
      " [   0 1359]] \n",
      "\n",
      "True negative: 2091 , false positive: 0 , false negative: 0 ,true positive: 1359 \n",
      "\n",
      "Accuracy score 1.0 \n",
      "\n",
      "Precision 1.0 \n",
      "\n",
      "Recall 1.0 \n",
      "\n",
      "F1 score 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = clf.predict(X_train)\n",
    "\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(test_data, y_train), \"\\n\")\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_data, y_train).ravel()\n",
    "print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "\n",
    "print(\"Accuracy score\", accuracy_score(test_data, y_train), \"\\n\")\n",
    "\n",
    "print(\"Precision\", precision_score(test_data, y_train), \"\\n\")\n",
    "\n",
    "print(\"Recall\", recall_score(test_data, y_train), \"\\n\")\n",
    "\n",
    "print(\"F1 score\", f1_score(test_data, y_train), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    def match(self, example):\n",
    "        if self.column in example:\n",
    "            val = example[self.column]\n",
    "            if Util.is_numeric(val):\n",
    "                return val >= self.value\n",
    "            else:\n",
    "                return val == self.value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if Util.is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header[self.column], condition, str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement decision tree classifier for numerical feature\n",
    "import time\n",
    "\n",
    "class Util:\n",
    "    @staticmethod\n",
    "    def label_count(labels):\n",
    "        count = {}\n",
    "        for r in labels:\n",
    "            if r not in count:\n",
    "                count[r] = 0\n",
    "            count[r] += 1\n",
    "        return count\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_numeric(val):\n",
    "        return isinstance(val, int) or isinstance(val, float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition(X, y, pred):\n",
    "        true_X, false_X, true_y, false_y = [], [], [], []\n",
    "        \n",
    "        for x_inst, y_inst  in zip(X, y):\n",
    "            if pred.match(x_inst):\n",
    "                true_X.append(x_inst)\n",
    "                true_y.append(y_inst)\n",
    "            else:\n",
    "                false_X.append(x_inst)\n",
    "                false_y.append(y_inst)\n",
    "        return true_X, true_y, false_X, false_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_impur(labels):\n",
    "        \"\"\"\n",
    "        Gini impurity\n",
    "        \"\"\"\n",
    "        counts = Util.label_count(labels)\n",
    "        total = 0\n",
    "        for lbl in counts:\n",
    "            prob_of_lbl = float(counts[lbl]) / len(labels)\n",
    "            total += (prob_of_lbl * prob_of_lbl)\n",
    "        return 1 - total\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_gain(leftLbl, rightLbl, curr_uncertainty):\n",
    "        \"\"\"\n",
    "        Calculating information gain\n",
    "        \"\"\"\n",
    "        p = float (len(leftLbl)) / (len(leftLbl) + len(rightLbl))\n",
    "        return curr_uncertainty - p * Util.gini_impur(leftLbl) - (1 - p) * Util.gini_impur(rightLbl)\n",
    "        \n",
    "class Leaf:\n",
    "    def __init__(self, y):\n",
    "        pred = Util.label_count(y)\n",
    "        for l in pred:\n",
    "            pred[l] = pred[l] / len(y)\n",
    "        self.predictions = pred\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return True\n",
    "\n",
    "class DecTreeNode:\n",
    "    def __init__(self, pred, true_branch, false_branch):\n",
    "        self.pred = pred\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return False\n",
    "    \n",
    "class DecTreeClassifier:\n",
    "    def __init__(self, max_depth=10):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def findBestSplit(self, X, y):\n",
    "        start = time.time()\n",
    "        best_gain = 0  \n",
    "        best_pred = None\n",
    "        current_uncert = Util.gini_impur(y)\n",
    "        n_features = np.array(X).shape[1]\n",
    "        \n",
    "        for col in range(n_features):\n",
    "            vals = set([row[col] for row in X]) # different values in column\n",
    "            \n",
    "            for v in vals:\n",
    "                pred = Predicate(col, v)\n",
    "                true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "                \n",
    "                if len(true_X) == 0 or len(false_X) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = Util.info_gain(true_y, false_y, current_uncert)\n",
    "                \n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_pred = gain, pred\n",
    "        print(\"Find best split size\", np.array(X).shape, \"took\", time.time() - start)\n",
    "        return best_gain, best_pred\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        gain, pred = self.findBestSplit(X, y)\n",
    "        if gain == 0 or depth == self.max_depth:\n",
    "            return Leaf(y)\n",
    "        true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "        \n",
    "        true_branch = self.build_tree(true_X, true_y, depth + 1)\n",
    "        false_branch = self.build_tree(false_X, false_y, depth + 1)\n",
    "        \n",
    "        return DecTreeNode(pred, true_branch, false_branch)\n",
    "    \n",
    "    def predict_by_tree(self, tree, X_inst):\n",
    "        if tree.isLeaf():\n",
    "            return tree.predictions\n",
    "        elif tree.pred.match(X_inst):\n",
    "            return self.predict_by_tree(tree.true_branch, X_inst)\n",
    "        else:\n",
    "            return self.predict_by_tree(tree.false_branch, X_inst)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(X.values, y.values) \n",
    "    \n",
    "    def predict_instance(self, X_inst):\n",
    "        return self.predict_by_tree(self.tree, X_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find best split size (1000, 57) took 31.084879636764526\n",
      "Find best split size (226, 57) took 2.7360053062438965\n",
      "Find best split size (6, 57) took 0.003379344940185547\n",
      "Find best split size (220, 57) took 2.63153338432312\n",
      "Find best split size (6, 57) took 0.0031824111938476562\n",
      "Find best split size (214, 57) took 2.5530741214752197\n",
      "Find best split size (4, 57) took 0.0020666122436523438\n",
      "Find best split size (210, 57) took 2.4417262077331543\n",
      "Find best split size (3, 57) took 0.0017087459564208984\n",
      "Find best split size (207, 57) took 2.377399444580078\n",
      "Find best split size (3, 57) took 0.0014438629150390625\n",
      "Find best split size (204, 57) took 2.340468406677246\n",
      "Find best split size (7, 57) took 0.004323482513427734\n",
      "Find best split size (4, 57) took 0.0020818710327148438\n",
      "Find best split size (2, 57) took 0.0008363723754882812\n",
      "Find best split size (2, 57) took 0.0009479522705078125\n",
      "Find best split size (3, 57) took 0.0013141632080078125\n",
      "Find best split size (197, 57) took 2.1974854469299316\n",
      "Find best split size (2, 57) took 0.0010097026824951172\n",
      "Find best split size (195, 57) took 2.379613161087036\n",
      "Find best split size (2, 57) took 0.0008454322814941406\n",
      "Find best split size (193, 57) took 2.1035077571868896\n",
      "Find best split size (4, 57) took 0.0022766590118408203\n",
      "Find best split size (189, 57) took 2.016270637512207\n",
      "Find best split size (774, 57) took 17.081897020339966\n",
      "Find best split size (90, 57) took 0.13786697387695312\n",
      "Find best split size (2, 57) took 0.0009553432464599609\n",
      "Find best split size (88, 57) took 0.12099266052246094\n",
      "Find best split size (1, 57) took 0.0010306835174560547\n",
      "Find best split size (87, 57) took 0.12013983726501465\n",
      "Find best split size (1, 57) took 0.0004391670227050781\n",
      "Find best split size (86, 57) took 0.1064915657043457\n",
      "Find best split size (12, 57) took 0.004923582077026367\n",
      "Find best split size (3, 57) took 0.0011510848999023438\n",
      "Find best split size (9, 57) took 0.0038733482360839844\n",
      "Find best split size (3, 57) took 0.0016703605651855469\n",
      "Find best split size (6, 57) took 0.0022335052490234375\n",
      "Find best split size (74, 57) took 0.09860348701477051\n",
      "Find best split size (684, 57) took 16.391435623168945\n",
      "Find best split size (41, 57) took 0.054457664489746094\n",
      "Find best split size (2, 57) took 0.0009315013885498047\n",
      "Find best split size (39, 57) took 0.03986334800720215\n",
      "Find best split size (1, 57) took 0.0004401206970214844\n",
      "Find best split size (38, 57) took 0.03795433044433594\n",
      "Find best split size (1, 57) took 0.00042438507080078125\n",
      "Find best split size (37, 57) took 0.03552961349487305\n",
      "Find best split size (643, 57) took 15.22620153427124\n",
      "Find best split size (52, 57) took 0.08056926727294922\n",
      "Find best split size (3, 57) took 0.0016591548919677734\n",
      "Find best split size (1, 57) took 0.0004343986511230469\n",
      "Find best split size (2, 57) took 0.001051187515258789\n",
      "Find best split size (49, 57) took 0.06346869468688965\n",
      "Find best split size (1, 57) took 0.000431060791015625\n",
      "Find best split size (48, 57) took 0.05823254585266113\n",
      "Find best split size (1, 57) took 0.0008528232574462891\n",
      "Find best split size (47, 57) took 0.06769394874572754\n",
      "Find best split size (2, 57) took 0.0008497238159179688\n",
      "Find best split size (45, 57) took 0.05109357833862305\n",
      "Find best split size (2, 57) took 0.0007889270782470703\n",
      "Find best split size (1, 57) took 0.000431060791015625\n",
      "Find best split size (1, 57) took 0.00042939186096191406\n",
      "Find best split size (43, 57) took 0.047550201416015625\n",
      "Find best split size (3, 57) took 0.001127004623413086\n",
      "Find best split size (40, 57) took 0.04076814651489258\n",
      "Find best split size (591, 57) took 11.930394649505615\n",
      "Find best split size (26, 57) took 0.0267791748046875\n",
      "Find best split size (1, 57) took 0.00043010711669921875\n",
      "Find best split size (25, 57) took 0.025614023208618164\n",
      "Find best split size (3, 57) took 0.0011734962463378906\n",
      "Find best split size (22, 57) took 0.02037501335144043\n",
      "Find best split size (2, 57) took 0.0008783340454101562\n",
      "Find best split size (20, 57) took 0.017176389694213867\n",
      "Find best split size (2, 57) took 0.0006933212280273438\n",
      "Find best split size (18, 57) took 0.014662027359008789\n",
      "Find best split size (1, 57) took 0.00043654441833496094\n",
      "Find best split size (17, 57) took 0.01468205451965332\n",
      "Find best split size (565, 57) took 11.427468538284302\n",
      "Find best split size (28, 57) took 0.05123186111450195\n",
      "Find best split size (1, 57) took 0.0004937648773193359\n",
      "Find best split size (27, 57) took 0.03666257858276367\n",
      "Find best split size (1, 57) took 0.00043964385986328125\n",
      "Find best split size (26, 57) took 0.031822919845581055\n",
      "Find best split size (2, 57) took 0.0008265972137451172\n",
      "Find best split size (1, 57) took 0.0004277229309082031\n",
      "Find best split size (1, 57) took 0.0004227161407470703\n",
      "Find best split size (24, 57) took 0.0348358154296875\n",
      "Find best split size (2, 57) took 0.0008792877197265625\n",
      "Find best split size (22, 57) took 0.026793956756591797\n",
      "Find best split size (537, 57) took 10.360692262649536\n",
      "Find best split size (31, 57) took 0.037830352783203125\n",
      "Find best split size (3, 57) took 0.0013308525085449219\n",
      "Find best split size (28, 57) took 0.03118729591369629\n",
      "Find best split size (2, 57) took 0.0007948875427246094\n",
      "Find best split size (26, 57) took 0.028310775756835938\n",
      "Find best split size (2, 57) took 0.0008535385131835938\n",
      "Find best split size (24, 57) took 0.024071455001831055\n",
      "Find best split size (506, 57) took 9.553033351898193\n",
      "Find best split size (25, 57) took 0.04135775566101074\n",
      "Find best split size (1, 57) took 0.00044155120849609375\n",
      "Find best split size (24, 57) took 0.040116071701049805\n",
      "Find best split size (1, 57) took 0.00042319297790527344\n",
      "Find best split size (23, 57) took 0.03784012794494629\n",
      "Find best split size (481, 57) took 8.618022441864014\n",
      "Find best split size (16, 57) took 0.010864496231079102\n",
      "Find best split size (1, 57) took 0.00045299530029296875\n",
      "Find best split size (15, 57) took 0.00980687141418457\n",
      "Find best split size (465, 57) took 8.226831197738647\n",
      "Find best split size (42, 57) took 0.06261825561523438\n",
      "Find best split size (423, 57) took 8.297021865844727\n",
      "Decision tree classifier take 173.8864986896515 seconds to build tree\n"
     ]
    }
   ],
   "source": [
    "decTreeClf = DecTreeClassifier()\n",
    "start = time.time()\n",
    "decTreeClf.fit(X_train[:1000], y_train[:1000])\n",
    "print(\"Decision tree classifier take\", time.time() - start, \"seconds to build tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.8823529411764706, 1.0: 0.11764705882352941}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decTreeClf.predict_instance(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTreeClf.predict(X_test[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, num_est=10):\n",
    "        self.num_est = num_est\n",
    "        self.forest = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Bagging\n",
    "        for i in range(self.num_est):\n",
    "            X_samp, y_samp = resample(X, y, replace=True, random_state=0)\n",
    "            clf = DecTreeClassifier()\n",
    "            clf.fit(X_samp, y_samp)\n",
    "            self.forest.append(clf)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        labels = {}\n",
    "        for clf in self.forest:\n",
    "            y = clf.predict(X)\n",
    "            if y not in labels:\n",
    "                labels[y] = 0\n",
    "            labels[y] += 1\n",
    "        \n",
    "        for l in labels:\n",
    "            labels[l] = labels[i] / self.num_est\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10), n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfierData(clf):\n",
    "    test_data = clf.predict(X_test)\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(test_data, y_test), \"\\n\")\n",
    "    tn, fp, fn, tp = confusion_matrix(test_data, y_test).ravel()\n",
    "    print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "    print(\"Accuracy score\", accuracy_score(test_data, y_test), \"\\n\")\n",
    "    print(\"Precision\", precision_score(test_data, y_test), \"\\n\")\n",
    "    print(\"Recall\", recall_score(test_data, y_test), \"\\n\")\n",
    "    print(\"F1 score\", f1_score(test_data, y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[676  40]\n",
      " [ 21 414]] \n",
      "\n",
      "True negative: 676 , false positive: 40 , false negative: 21 ,true positive: 414 \n",
      "\n",
      "Accuracy score 0.947002606429192 \n",
      "\n",
      "Precision 0.9118942731277533 \n",
      "\n",
      "Recall 0.9517241379310345 \n",
      "\n",
      "F1 score 0.9313835770528683 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
