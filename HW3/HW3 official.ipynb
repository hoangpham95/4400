{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to HW is [here](https://github.com/hoangpham95/4400/blob/master/HW3/HW3%20official.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "matrix = []\n",
    "\n",
    "with open(\"spambase.data\", \"r\") as raw_data:\n",
    "    for raw_line in raw_data:\n",
    "        line = [float(x) for x in raw_line.split(\",\")]\n",
    "        matrix.append(line)\n",
    "\n",
    "data = pd.DataFrame(matrix)\n",
    "row, col = data.shape\n",
    "X, y = data.iloc[:,:col - 1], data[col - 1]\n",
    "# y = y.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest Classifier on existing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfierData(clf, X, y):\n",
    "    test_data = clf.predict(X)\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(test_data, y), \"\\n\")\n",
    "    tn, fp, fn, tp = confusion_matrix(test_data, y).ravel()\n",
    "    print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "    print(\"Accuracy score\", accuracy_score(test_data, y), \"\\n\")\n",
    "    print(\"Precision\", precision_score(test_data, y), \"\\n\")\n",
    "    print(\"Recall\", recall_score(test_data, y), \"\\n\")\n",
    "    print(\"F1 score\", f1_score(test_data, y), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[2091    2]\n",
      " [   0 1357]] \n",
      "\n",
      "True negative: 2091 , false positive: 2 , false negative: 0 ,true positive: 1357 \n",
      "\n",
      "Accuracy score 0.9994202898550725 \n",
      "\n",
      "Precision 0.9985283296541575 \n",
      "\n",
      "Recall 1.0 \n",
      "\n",
      "F1 score 0.9992636229749632 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[673  37]\n",
      " [ 24 417]] \n",
      "\n",
      "True negative: 673 , false positive: 37 , false negative: 24 ,true positive: 417 \n",
      "\n",
      "Accuracy score 0.947002606429192 \n",
      "\n",
      "Precision 0.9185022026431718 \n",
      "\n",
      "Recall 0.9455782312925171 \n",
      "\n",
      "F1 score 0.9318435754189944 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing own Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicate class acts as the splitting question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    def match(self, example, pp=False):\n",
    "        if pp:\n",
    "            print(\"Match on column\", self.column)\n",
    "        val = example[self.column]\n",
    "        if Util.is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Question: column {}, value {}'.format(self.column, self.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility functions that being reused a lot in the implementation of random forest. In this implementation, I used gini impurity instead of entropy since `log` function would arguably take longer to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Util:\n",
    "    @staticmethod\n",
    "    def label_count(labels):\n",
    "        count = {}\n",
    "        for r in labels:\n",
    "            if r not in count:\n",
    "                count[r] = 0\n",
    "            count[r] += 1\n",
    "        return count\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_numeric(val):\n",
    "        return isinstance(val, int) or isinstance(val, float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition(X, y, pred):\n",
    "        true_X, false_X, true_y, false_y = [], [], [], []\n",
    "        \n",
    "        for x_inst, y_inst in zip(X, y):\n",
    "            if pred.match(x_inst):\n",
    "                true_X.append(x_inst)\n",
    "                true_y.append(y_inst)\n",
    "            else:\n",
    "                false_X.append(x_inst)\n",
    "                false_y.append(y_inst)\n",
    "        return true_X, true_y, false_X, false_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_impur(labels):\n",
    "        \"\"\"\n",
    "        Gini impurity\n",
    "        \"\"\"\n",
    "        counts = Util.label_count(labels)\n",
    "        total = 0\n",
    "        for lbl in counts:\n",
    "            prob_of_lbl = float(counts[lbl]) / len(labels)\n",
    "            total += (prob_of_lbl * prob_of_lbl)\n",
    "        return 1 - total\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_gain(leftLbl, rightLbl, curr_uncertainty):\n",
    "        \"\"\"\n",
    "        Calculating information gain\n",
    "        \"\"\"\n",
    "        p = float (len(leftLbl)) / (len(leftLbl) + len(rightLbl))\n",
    "        return curr_uncertainty - p * Util.gini_impur(leftLbl) - (1 - p) * Util.gini_impur(rightLbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, y, depth=0):\n",
    "        self.depth = depth\n",
    "        pred = Util.label_count(y)\n",
    "        for l in pred:\n",
    "            pred[l] = pred[l] / len(y)\n",
    "        self.predictions = pred\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return True\n",
    "\n",
    "class DecTreeNode:\n",
    "    def __init__(self, pred, true_branch, false_branch, depth=0):\n",
    "        self.depth = depth\n",
    "        self.pred = pred\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecTreeClassifier:\n",
    "    def __init__(self, max_depth=10):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def findBestSplit(self, X, y, pp=False):\n",
    "        start = time.time()\n",
    "        best_gain = 0  \n",
    "        best_pred = None\n",
    "        current_uncert = Util.gini_impur(y)\n",
    "        \n",
    "        for col in self.selected_features:\n",
    "            vals = set([row[col] for row in X]) # different values in column\n",
    "            \n",
    "            for v in vals:\n",
    "                pred = Predicate(col, v)\n",
    "                true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "                \n",
    "                if len(true_X) == 0 or len(false_X) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = Util.info_gain(true_y, false_y, current_uncert)\n",
    "                \n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_pred = gain, pred\n",
    "        if pp:\n",
    "            print(\"Find best split size\", np.array(X).shape, \"took\", time.time() - start)\n",
    "        return best_gain, best_pred\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        gain, pred = self.findBestSplit(X, y)\n",
    "        if gain == 0 or depth >= self.max_depth:\n",
    "            return Leaf(y, depth)\n",
    "        true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "        \n",
    "        true_branch = self.build_tree(true_X, true_y, depth + 1)\n",
    "        false_branch = self.build_tree(false_X, false_y, depth + 1)\n",
    "        \n",
    "        return DecTreeNode(pred, true_branch, false_branch)\n",
    "    \n",
    "    def predict_by_tree(self, tree, X_inst):\n",
    "        if tree.isLeaf():\n",
    "            return tree.predictions\n",
    "        elif tree.pred.match(X_inst, pp=False):\n",
    "            return self.predict_by_tree(tree.true_branch, X_inst)\n",
    "        else:\n",
    "            return self.predict_by_tree(tree.false_branch, X_inst)\n",
    "    \n",
    "    def fit(self, X, y, selected_features=None):\n",
    "        if selected_features is None:\n",
    "            self.selected_features = X.columns\n",
    "        else:\n",
    "            self.selected_features = selected_features\n",
    "            \n",
    "        self.tree = self.build_tree(X.values, y.values) \n",
    "    \n",
    "    def predict_inst(self, X_inst):\n",
    "        pred = self.predict_by_tree(self.tree, np.array(X_inst))\n",
    "        max_arg, max_prob = None, 0\n",
    "        for l in pred:\n",
    "            if pred[l] > max_prob:\n",
    "                max_arg = l\n",
    "            max_prob = max(max_prob, pred[l])\n",
    "        return max_arg\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for idx, r in X.iterrows():\n",
    "            y.append(self.predict_inst(r))\n",
    "        return pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier take 258.04462361335754 seconds to build tree\n"
     ]
    }
   ],
   "source": [
    "# Training decision tree\n",
    "decTreeClf = DecTreeClassifier(max_depth=10)\n",
    "start = time.time()\n",
    "decTreeClf.fit(X_train, y_train)\n",
    "print(\"Decision tree classifier take\", time.time() - start, \"seconds to build tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to build a full tree with depth 10, it took me 247 seconds (~4 minutes). Having max depth helps us limit the training time and also avoid overfitting on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[657  54]\n",
      " [ 40 400]] \n",
      "\n",
      "True negative: 657 , false positive: 54 , false negative: 40 ,true positive: 400 \n",
      "\n",
      "Accuracy score 0.9183318853171155 \n",
      "\n",
      "Precision 0.8810572687224669 \n",
      "\n",
      "Recall 0.9090909090909091 \n",
      "\n",
      "F1 score 0.894854586129754 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(decTreeClf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[654  54]\n",
      " [ 43 400]] \n",
      "\n",
      "True negative: 654 , false positive: 54 , false negative: 43 ,true positive: 400 \n",
      "\n",
      "Accuracy score 0.9157254561251086 \n",
      "\n",
      "Precision 0.8810572687224669 \n",
      "\n",
      "Recall 0.9029345372460497 \n",
      "\n",
      "F1 score 0.8918617614269787 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dcf = DecisionTreeClassifier(max_depth=10)\n",
    "dcf.fit(X_train, y_train)\n",
    "classfierData(dcf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, my implementation of Decision Tree Classifier gains approximately the same result as sklearn's Decision Tree Classifier (less than 1% different in accuracy, precision, etc.). Now we can implement random forest classifier after decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import random\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, num_est=10, max_depth=5, num_attrs=5):\n",
    "        self.num_est = num_est\n",
    "        self.max_depth = max_depth\n",
    "        self.forest = []\n",
    "        self.num_attrs = num_attrs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Bagging\n",
    "        for i in range(self.num_est):\n",
    "            shape = len(X.columns)\n",
    "            \n",
    "            selected_features = random.sample(range(0, shape), self.num_attrs)\n",
    "            X_samp, y_samp = resample(X, y, replace=True)\n",
    "            clf = DecTreeClassifier(max_depth=self.max_depth)\n",
    "            print(\"Selected features\", selected_features)\n",
    "            start = time.time()\n",
    "            print(\"=== Training estimator #\", i + 1, \"with\", len(selected_features),\"features\")\n",
    "            clf.fit(X_samp, y_samp, selected_features=selected_features)\n",
    "            print(\"===> Done training estimator #\", i + 1, \"in\", time.time() - start, \"seconds\")\n",
    "            self.forest.append(clf)\n",
    "            print(\"--------------------------------------------------------------\\n\")\n",
    "            \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for idx, x in X.iterrows():\n",
    "            labels = {}\n",
    "            for clf in self.forest:\n",
    "                l = clf.predict_inst(x)\n",
    "                if l not in labels:\n",
    "                    labels[l] = 0\n",
    "                labels[l] += 1\n",
    "            for l in labels:\n",
    "                if labels[l] >= 0.5:\n",
    "                    result.append(l)\n",
    "                    break\n",
    "        return pd.DataFrame(result)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing random forest on $\\sqrt{d}$ attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features [51, 26, 36, 54, 12, 4, 43]\n",
      "=== Training estimator # 1 with 7 features\n",
      "===> Done training estimator # 1 in 27.395561933517456 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [2, 32, 1, 20, 19, 27, 47]\n",
      "=== Training estimator # 2 with 7 features\n",
      "===> Done training estimator # 2 in 11.714879274368286 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [42, 54, 55, 46, 51, 38, 56]\n",
      "=== Training estimator # 3 with 7 features\n",
      "===> Done training estimator # 3 in 35.14453482627869 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [35, 28, 34, 25, 50, 42, 17]\n",
      "=== Training estimator # 4 with 7 features\n",
      "===> Done training estimator # 4 in 10.402256488800049 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [5, 13, 23, 50, 20, 46, 9]\n",
      "=== Training estimator # 5 with 7 features\n",
      "===> Done training estimator # 5 in 11.258687257766724 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [46, 43, 45, 53, 47, 38, 19]\n",
      "=== Training estimator # 6 with 7 features\n",
      "===> Done training estimator # 6 in 8.58342432975769 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [25, 2, 35, 36, 41, 4, 13]\n",
      "=== Training estimator # 7 with 7 features\n",
      "===> Done training estimator # 7 in 10.901612281799316 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [1, 34, 33, 53, 36, 46, 7]\n",
      "=== Training estimator # 8 with 7 features\n",
      "===> Done training estimator # 8 in 8.692519903182983 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [4, 47, 43, 23, 29, 13, 19]\n",
      "=== Training estimator # 9 with 7 features\n",
      "===> Done training estimator # 9 in 9.095300436019897 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [18, 22, 48, 49, 19, 6, 41]\n",
      "=== Training estimator # 10 with 7 features\n",
      "===> Done training estimator # 10 in 23.02400517463684 seconds\n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[629 100]\n",
      " [ 68 354]] \n",
      "\n",
      "True negative: 629 , false positive: 100 , false negative: 68 ,true positive: 354 \n",
      "\n",
      "Accuracy score 0.8540399652476107 \n",
      "\n",
      "Precision 0.7797356828193832 \n",
      "\n",
      "Recall 0.8388625592417062 \n",
      "\n",
      "F1 score 0.8082191780821917 \n",
      "\n",
      "Confusion matrix\n",
      " [[1969  191]\n",
      " [ 122 1168]] \n",
      "\n",
      "True negative: 1969 , false positive: 191 , false negative: 122 ,true positive: 1168 \n",
      "\n",
      "Accuracy score 0.9092753623188405 \n",
      "\n",
      "Precision 0.8594554819720382 \n",
      "\n",
      "Recall 0.9054263565891473 \n",
      "\n",
      "F1 score 0.8818422046055114 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(rfc, X_test, y_test)\n",
    "classfierData(rfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest on all attributes with 10 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features [6, 48, 7, 13, 30, 2, 39, 12, 16, 38, 20, 26, 11, 32, 21, 23, 0, 36, 14, 34, 33, 25, 56, 31, 29, 49, 53, 19, 27, 8, 42, 22, 54, 5, 3, 52, 44, 43, 50, 18, 17, 35, 15, 46, 37, 45, 24, 9, 51, 55, 40, 10, 47, 1, 28, 4, 41]\n",
      "=== Training estimator # 1 with 57 features\n",
      "===> Done training estimator # 1 in 184.23791527748108 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [25, 10, 1, 33, 17, 21, 14, 12, 20, 4, 0, 51, 40, 49, 31, 27, 48, 39, 47, 56, 55, 46, 38, 13, 7, 26, 54, 24, 6, 45, 37, 29, 3, 32, 44, 53, 52, 43, 16, 22, 8, 2, 30, 15, 50, 23, 35, 18, 34, 36, 19, 9, 41, 28, 42, 11, 5]\n",
      "=== Training estimator # 2 with 57 features\n",
      "===> Done training estimator # 2 in 183.29053115844727 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [31, 12, 51, 55, 42, 46, 30, 26, 47, 27, 2, 1, 20, 7, 52, 43, 8, 41, 35, 22, 4, 21, 0, 37, 32, 38, 3, 29, 54, 13, 33, 18, 53, 50, 17, 34, 24, 45, 11, 48, 9, 28, 5, 49, 44, 15, 23, 36, 56, 10, 19, 14, 6, 16, 40, 25, 39]\n",
      "=== Training estimator # 3 with 57 features\n",
      "===> Done training estimator # 3 in 180.56338763237 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [46, 45, 38, 27, 31, 23, 47, 52, 42, 53, 24, 48, 28, 33, 50, 0, 13, 2, 4, 35, 8, 51, 49, 6, 5, 20, 40, 56, 10, 3, 25, 30, 37, 12, 21, 9, 26, 16, 41, 17, 34, 11, 55, 19, 43, 14, 44, 36, 39, 18, 32, 29, 15, 54, 7, 22, 1]\n",
      "=== Training estimator # 4 with 57 features\n",
      "===> Done training estimator # 4 in 199.36548805236816 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [54, 22, 11, 9, 3, 2, 39, 44, 26, 14, 33, 48, 32, 17, 41, 37, 21, 52, 31, 42, 38, 16, 46, 50, 8, 49, 1, 43, 27, 34, 24, 51, 25, 40, 55, 10, 47, 5, 7, 6, 29, 15, 53, 30, 18, 19, 12, 0, 23, 45, 20, 28, 13, 56, 35, 4, 36]\n",
      "=== Training estimator # 5 with 57 features\n",
      "===> Done training estimator # 5 in 171.92680740356445 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [30, 28, 37, 42, 52, 21, 40, 56, 18, 27, 11, 1, 25, 4, 0, 50, 5, 8, 17, 47, 36, 20, 39, 33, 54, 45, 35, 46, 19, 44, 49, 13, 53, 23, 16, 26, 6, 38, 15, 48, 24, 2, 29, 31, 14, 9, 22, 51, 55, 32, 7, 43, 3, 12, 34, 41, 10]\n",
      "=== Training estimator # 6 with 57 features\n",
      "===> Done training estimator # 6 in 198.5089612007141 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [29, 28, 9, 32, 5, 42, 13, 45, 55, 38, 54, 26, 11, 18, 4, 39, 10, 46, 6, 34, 24, 49, 52, 50, 43, 53, 23, 14, 1, 20, 3, 48, 41, 27, 21, 19, 16, 35, 25, 33, 56, 31, 44, 47, 37, 40, 22, 2, 12, 8, 51, 17, 7, 0, 36, 30, 15]\n",
      "=== Training estimator # 7 with 57 features\n",
      "===> Done training estimator # 7 in 202.9568703174591 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [40, 23, 56, 19, 26, 5, 30, 16, 2, 31, 12, 46, 29, 47, 17, 33, 52, 41, 55, 49, 1, 0, 21, 45, 14, 42, 32, 3, 38, 39, 9, 8, 24, 6, 4, 27, 43, 54, 18, 28, 35, 13, 53, 7, 25, 11, 22, 34, 37, 15, 50, 44, 51, 36, 48, 10, 20]\n",
      "=== Training estimator # 8 with 57 features\n",
      "===> Done training estimator # 8 in 185.92561292648315 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [3, 52, 56, 29, 9, 18, 24, 50, 14, 23, 32, 27, 28, 7, 13, 55, 12, 0, 41, 43, 35, 31, 44, 6, 39, 47, 42, 33, 49, 21, 46, 17, 54, 15, 5, 20, 48, 51, 36, 8, 22, 4, 40, 38, 37, 11, 53, 30, 34, 1, 45, 2, 19, 16, 10, 25, 26]\n",
      "=== Training estimator # 9 with 57 features\n",
      "===> Done training estimator # 9 in 199.77438974380493 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [5, 51, 16, 7, 2, 22, 11, 14, 41, 4, 43, 28, 50, 24, 55, 18, 38, 17, 3, 48, 26, 12, 54, 30, 13, 40, 0, 35, 39, 42, 23, 20, 8, 56, 33, 15, 37, 1, 31, 19, 36, 10, 25, 6, 52, 44, 45, 21, 32, 47, 53, 49, 9, 34, 29, 27, 46]\n",
      "=== Training estimator # 10 with 57 features\n",
      "===> Done training estimator # 10 in 215.04466938972473 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[642  56]\n",
      " [ 55 398]] \n",
      "\n",
      "True negative: 642 , false positive: 56 , false negative: 55 ,true positive: 398 \n",
      "\n",
      "Accuracy score 0.9035621198957429 \n",
      "\n",
      "Precision 0.8766519823788547 \n",
      "\n",
      "Recall 0.8785871964679912 \n",
      "\n",
      "F1 score 0.8776185226019847 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=57)\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features [20, 1, 14, 41, 51, 44, 17, 36, 9, 55, 6, 34, 26, 48, 13, 28, 50, 3, 25, 37, 47, 32, 43, 56, 31, 4, 21, 49]\n",
      "=== Training estimator # 1 with 28 features\n",
      "===> Done training estimator # 1 in 73.9450249671936 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [25, 19, 12, 55, 13, 4, 37, 8, 33, 45, 31, 56, 9, 53, 36, 29, 22, 54, 40, 41, 20, 5, 17, 30, 11, 15, 16, 24]\n",
      "=== Training estimator # 2 with 28 features\n",
      "===> Done training estimator # 2 in 83.8211739063263 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [13, 29, 0, 3, 28, 52, 19, 35, 51, 23, 9, 10, 50, 21, 48, 5, 4, 39, 44, 32, 26, 30, 55, 25, 22, 38, 56, 49]\n",
      "=== Training estimator # 3 with 28 features\n",
      "===> Done training estimator # 3 in 85.79024934768677 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [47, 36, 15, 33, 9, 6, 5, 56, 18, 4, 14, 53, 43, 32, 52, 28, 21, 23, 3, 24, 44, 39, 51, 13, 0, 7, 34, 41]\n",
      "=== Training estimator # 4 with 28 features\n",
      "===> Done training estimator # 4 in 82.44169330596924 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [3, 30, 19, 6, 41, 48, 13, 54, 18, 25, 16, 42, 38, 14, 4, 2, 35, 11, 32, 43, 34, 31, 46, 45, 5, 7, 50, 39]\n",
      "=== Training estimator # 5 with 28 features\n",
      "===> Done training estimator # 5 in 68.2973644733429 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [21, 3, 48, 5, 31, 12, 40, 33, 54, 26, 23, 7, 56, 1, 17, 4, 18, 25, 27, 45, 51, 14, 28, 24, 19, 44, 16, 41]\n",
      "=== Training estimator # 6 with 28 features\n",
      "===> Done training estimator # 6 in 95.82085728645325 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [16, 22, 10, 42, 29, 37, 36, 39, 5, 40, 25, 6, 3, 50, 55, 1, 0, 53, 32, 54, 43, 2, 11, 13, 20, 15, 45, 31]\n",
      "=== Training estimator # 7 with 28 features\n",
      "===> Done training estimator # 7 in 76.4071774482727 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [20, 32, 19, 55, 1, 0, 44, 8, 51, 41, 12, 33, 34, 26, 39, 10, 13, 24, 18, 35, 3, 14, 45, 42, 48, 2, 53, 52]\n",
      "=== Training estimator # 8 with 28 features\n",
      "===> Done training estimator # 8 in 63.70781850814819 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [18, 31, 24, 30, 14, 52, 11, 4, 39, 37, 12, 47, 1, 22, 9, 29, 54, 27, 19, 55, 35, 26, 36, 15, 48, 38, 21, 53]\n",
      "=== Training estimator # 9 with 28 features\n",
      "===> Done training estimator # 9 in 78.38974714279175 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [46, 5, 39, 54, 26, 19, 24, 22, 50, 36, 31, 35, 1, 14, 34, 53, 11, 38, 17, 16, 43, 12, 51, 47, 28, 9, 4, 56]\n",
      "=== Training estimator # 10 with 28 features\n",
      "===> Done training estimator # 10 in 78.49882364273071 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[640  70]\n",
      " [ 57 384]] \n",
      "\n",
      "True negative: 640 , false positive: 70 , false negative: 57 ,true positive: 384 \n",
      "\n",
      "Accuracy score 0.889661164205039 \n",
      "\n",
      "Precision 0.8458149779735683 \n",
      "\n",
      "Recall 0.8707482993197279 \n",
      "\n",
      "F1 score 0.8581005586592179 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## With d/2 features\n",
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=int(57/2))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features [31, 42, 19, 54, 45, 35, 5]\n",
      "=== Training estimator # 1 with 7 features\n",
      "===> Done training estimator # 1 in 21.07187843322754 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [7, 44, 22, 27, 21, 47, 10]\n",
      "=== Training estimator # 2 with 7 features\n",
      "===> Done training estimator # 2 in 11.313880205154419 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [35, 16, 48, 43, 45, 3, 33]\n",
      "=== Training estimator # 3 with 7 features\n",
      "===> Done training estimator # 3 in 10.242543697357178 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [26, 55, 39, 51, 11, 25, 12]\n",
      "=== Training estimator # 4 with 7 features\n",
      "===> Done training estimator # 4 in 18.373183488845825 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [47, 15, 39, 4, 17, 9, 40]\n",
      "=== Training estimator # 5 with 7 features\n",
      "===> Done training estimator # 5 in 11.56716775894165 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [51, 3, 50, 0, 14, 2, 42]\n",
      "=== Training estimator # 6 with 7 features\n",
      "===> Done training estimator # 6 in 13.00388240814209 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [32, 25, 47, 40, 50, 22, 34]\n",
      "=== Training estimator # 7 with 7 features\n",
      "===> Done training estimator # 7 in 9.251607179641724 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [12, 23, 3, 21, 42, 8, 37]\n",
      "=== Training estimator # 8 with 7 features\n",
      "===> Done training estimator # 8 in 6.725144386291504 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [30, 36, 38, 5, 16, 50, 52]\n",
      "=== Training estimator # 9 with 7 features\n",
      "===> Done training estimator # 9 in 12.930679559707642 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [16, 25, 21, 30, 27, 47, 52]\n",
      "=== Training estimator # 10 with 7 features\n",
      "===> Done training estimator # 10 in 11.023927688598633 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[589 138]\n",
      " [108 316]] \n",
      "\n",
      "True negative: 589 , false positive: 138 , false negative: 108 ,true positive: 316 \n",
      "\n",
      "Accuracy score 0.7862728062554301 \n",
      "\n",
      "Precision 0.6960352422907489 \n",
      "\n",
      "Recall 0.7452830188679245 \n",
      "\n",
      "F1 score 0.7198177676537586 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with $\\sqrt{d}$ attributes and varying number of estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My implementation of random forest returns approximately 80% of accuracy across 3 models (first with 10 estimators, next with 50 estimators and last with 100 estimators). sklearn's package returns a more performant one with nearly 98-99% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features [38, 37, 35, 26, 25, 40, 28]\n",
      "=== Training estimator # 1 with 7 features\n",
      "===> Done training estimator # 1 in 8.193460464477539 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [36, 10, 26, 56, 52, 46, 1]\n",
      "=== Training estimator # 2 with 7 features\n",
      "===> Done training estimator # 2 in 15.2423574924469 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [9, 14, 56, 37, 20, 8, 41]\n",
      "=== Training estimator # 3 with 7 features\n",
      "===> Done training estimator # 3 in 15.116879224777222 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [23, 27, 41, 1, 0, 48, 37]\n",
      "=== Training estimator # 4 with 7 features\n",
      "===> Done training estimator # 4 in 10.245727300643921 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [52, 6, 43, 46, 13, 35, 42]\n",
      "=== Training estimator # 5 with 7 features\n",
      "===> Done training estimator # 5 in 8.636177778244019 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [56, 48, 33, 23, 32, 15, 5]\n",
      "=== Training estimator # 6 with 7 features\n",
      "===> Done training estimator # 6 in 16.050829887390137 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [47, 37, 6, 46, 11, 50, 52]\n",
      "=== Training estimator # 7 with 7 features\n",
      "===> Done training estimator # 7 in 11.147160291671753 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [21, 30, 47, 0, 5, 1, 24]\n",
      "=== Training estimator # 8 with 7 features\n",
      "===> Done training estimator # 8 in 7.618672132492065 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [44, 49, 40, 39, 11, 10, 17]\n",
      "=== Training estimator # 9 with 7 features\n",
      "===> Done training estimator # 9 in 19.843032598495483 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [45, 52, 2, 0, 39, 17, 47]\n",
      "=== Training estimator # 10 with 7 features\n",
      "===> Done training estimator # 10 in 12.471284627914429 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[346  10]\n",
      " [351 444]] \n",
      "\n",
      "True negative: 346 , false positive: 10 , false negative: 351 ,true positive: 444 \n",
      "\n",
      "Accuracy score 0.6863596872284969 \n",
      "\n",
      "Precision 0.9779735682819384 \n",
      "\n",
      "Recall 0.5584905660377358 \n",
      "\n",
      "F1 score 0.7109687750200161 \n",
      "\n",
      "*****************************************************************************************\n",
      "\n",
      "Selected features [30, 46, 52, 17, 26, 36, 31]\n",
      "=== Training estimator # 1 with 7 features\n",
      "===> Done training estimator # 1 in 9.865459442138672 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [2, 17, 9, 33, 3, 39, 25]\n",
      "=== Training estimator # 2 with 7 features\n",
      "===> Done training estimator # 2 in 9.584921598434448 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [51, 52, 39, 19, 18, 50, 26]\n",
      "=== Training estimator # 3 with 7 features\n",
      "===> Done training estimator # 3 in 21.489988327026367 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [2, 18, 25, 39, 35, 43, 4]\n",
      "=== Training estimator # 4 with 7 features\n",
      "===> Done training estimator # 4 in 15.741608381271362 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [25, 14, 8, 29, 2, 42, 30]\n",
      "=== Training estimator # 5 with 7 features\n",
      "===> Done training estimator # 5 in 8.392758131027222 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [24, 17, 42, 9, 38, 33, 48]\n",
      "=== Training estimator # 6 with 7 features\n",
      "===> Done training estimator # 6 in 11.77037239074707 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [50, 9, 32, 35, 10, 3, 12]\n",
      "=== Training estimator # 7 with 7 features\n",
      "===> Done training estimator # 7 in 9.11807656288147 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [35, 56, 37, 45, 9, 4, 33]\n",
      "=== Training estimator # 8 with 7 features\n",
      "===> Done training estimator # 8 in 13.596971273422241 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [16, 6, 44, 23, 3, 38, 4]\n",
      "=== Training estimator # 9 with 7 features\n",
      "===> Done training estimator # 9 in 11.884703159332275 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [55, 10, 12, 48, 38, 16, 54]\n",
      "=== Training estimator # 10 with 7 features\n",
      "===> Done training estimator # 10 in 21.715354681015015 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [13, 24, 32, 49, 12, 19, 11]\n",
      "=== Training estimator # 11 with 7 features\n",
      "===> Done training estimator # 11 in 17.123014211654663 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [38, 51, 17, 21, 34, 48, 36]\n",
      "=== Training estimator # 12 with 7 features\n",
      "===> Done training estimator # 12 in 16.980400323867798 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [47, 42, 12, 30, 0, 43, 27]\n",
      "=== Training estimator # 13 with 7 features\n",
      "===> Done training estimator # 13 in 8.000771045684814 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [27, 9, 22, 49, 46, 14, 43]\n",
      "=== Training estimator # 14 with 7 features\n",
      "===> Done training estimator # 14 in 16.502405643463135 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [40, 49, 19, 50, 5, 44, 29]\n",
      "=== Training estimator # 15 with 7 features\n",
      "===> Done training estimator # 15 in 18.2013943195343 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [11, 35, 49, 54, 27, 51, 0]\n",
      "=== Training estimator # 16 with 7 features\n",
      "===> Done training estimator # 16 in 38.65618181228638 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [55, 24, 32, 49, 17, 27, 2]\n",
      "=== Training estimator # 17 with 7 features\n",
      "===> Done training estimator # 17 in 18.020139932632446 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [38, 34, 15, 35, 54, 29, 16]\n",
      "=== Training estimator # 18 with 7 features\n",
      "===> Done training estimator # 18 in 24.921257257461548 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [39, 35, 40, 48, 11, 15, 46]\n",
      "=== Training estimator # 19 with 7 features\n",
      "===> Done training estimator # 19 in 12.729244709014893 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [2, 6, 13, 23, 11, 40, 39]\n",
      "=== Training estimator # 20 with 7 features\n",
      "===> Done training estimator # 20 in 13.195272445678711 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [3, 15, 11, 24, 21, 6, 18]\n",
      "=== Training estimator # 21 with 7 features\n",
      "===> Done training estimator # 21 in 17.78747010231018 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [33, 44, 8, 5, 0, 24, 30]\n",
      "=== Training estimator # 22 with 7 features\n",
      "===> Done training estimator # 22 in 10.573413848876953 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [29, 18, 13, 2, 25, 37, 30]\n",
      "=== Training estimator # 23 with 7 features\n",
      "===> Done training estimator # 23 in 13.492450952529907 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [26, 9, 0, 52, 16, 7, 21]\n",
      "=== Training estimator # 24 with 7 features\n",
      "===> Done training estimator # 24 in 12.67800259590149 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [15, 51, 13, 45, 31, 53, 47]\n",
      "=== Training estimator # 25 with 7 features\n",
      "===> Done training estimator # 25 in 14.693440914154053 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [2, 16, 20, 6, 24, 31, 25]\n",
      "=== Training estimator # 26 with 7 features\n",
      "===> Done training estimator # 26 in 17.111408710479736 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [20, 26, 6, 7, 48, 46, 41]\n",
      "=== Training estimator # 27 with 7 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Done training estimator # 27 in 13.122714042663574 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [4, 22, 55, 14, 35, 23, 50]\n",
      "=== Training estimator # 28 with 7 features\n",
      "===> Done training estimator # 28 in 11.358417510986328 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [29, 4, 26, 49, 27, 13, 38]\n",
      "=== Training estimator # 29 with 7 features\n",
      "===> Done training estimator # 29 in 16.366130590438843 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [4, 32, 27, 50, 11, 56, 13]\n",
      "=== Training estimator # 30 with 7 features\n",
      "===> Done training estimator # 30 in 18.05549931526184 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [0, 21, 52, 27, 2, 41, 1]\n",
      "=== Training estimator # 31 with 7 features\n",
      "===> Done training estimator # 31 in 13.26807951927185 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [35, 1, 14, 40, 7, 8, 50]\n",
      "=== Training estimator # 32 with 7 features\n",
      "===> Done training estimator # 32 in 9.422818183898926 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [28, 52, 34, 43, 32, 3, 12]\n",
      "=== Training estimator # 33 with 7 features\n",
      "===> Done training estimator # 33 in 12.257339715957642 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [33, 18, 19, 46, 40, 15, 21]\n",
      "=== Training estimator # 34 with 7 features\n",
      "===> Done training estimator # 34 in 12.736237525939941 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [42, 0, 18, 23, 41, 54, 40]\n",
      "=== Training estimator # 35 with 7 features\n",
      "===> Done training estimator # 35 in 26.63769268989563 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [53, 20, 56, 52, 25, 37, 41]\n",
      "=== Training estimator # 36 with 7 features\n",
      "===> Done training estimator # 36 in 21.572200059890747 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [43, 30, 33, 31, 13, 20, 47]\n",
      "=== Training estimator # 37 with 7 features\n",
      "===> Done training estimator # 37 in 9.190176725387573 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [22, 29, 37, 25, 45, 16, 4]\n",
      "=== Training estimator # 38 with 7 features\n",
      "===> Done training estimator # 38 in 11.54965090751648 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [40, 54, 34, 24, 22, 14, 45]\n",
      "=== Training estimator # 39 with 7 features\n",
      "===> Done training estimator # 39 in 21.836592435836792 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [21, 32, 14, 49, 28, 24, 50]\n",
      "=== Training estimator # 40 with 7 features\n",
      "===> Done training estimator # 40 in 14.103811740875244 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [26, 46, 52, 42, 28, 15, 11]\n",
      "=== Training estimator # 41 with 7 features\n",
      "===> Done training estimator # 41 in 16.37380361557007 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [19, 23, 43, 2, 45, 53, 7]\n",
      "=== Training estimator # 42 with 7 features\n",
      "===> Done training estimator # 42 in 14.319404363632202 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [52, 54, 17, 20, 0, 2, 16]\n",
      "=== Training estimator # 43 with 7 features\n",
      "===> Done training estimator # 43 in 31.478728771209717 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [20, 19, 14, 15, 23, 26, 49]\n",
      "=== Training estimator # 44 with 7 features\n",
      "===> Done training estimator # 44 in 16.88729453086853 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [1, 54, 7, 23, 34, 5, 36]\n",
      "=== Training estimator # 45 with 7 features\n",
      "===> Done training estimator # 45 in 24.169631004333496 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [23, 27, 31, 46, 19, 2, 56]\n",
      "=== Training estimator # 46 with 7 features\n",
      "===> Done training estimator # 46 in 17.28704023361206 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [47, 48, 29, 41, 21, 33, 28]\n",
      "=== Training estimator # 47 with 7 features\n",
      "===> Done training estimator # 47 in 8.998664617538452 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [31, 50, 45, 9, 21, 6, 25]\n",
      "=== Training estimator # 48 with 7 features\n",
      "===> Done training estimator # 48 in 11.805469274520874 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [28, 18, 41, 34, 17, 29, 7]\n",
      "=== Training estimator # 49 with 7 features\n",
      "===> Done training estimator # 49 in 16.389532327651978 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [45, 49, 15, 30, 24, 2, 21]\n",
      "=== Training estimator # 50 with 7 features\n",
      "===> Done training estimator # 50 in 17.510870218276978 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[636 154]\n",
      " [ 61 300]] \n",
      "\n",
      "True negative: 636 , false positive: 154 , false negative: 61 ,true positive: 300 \n",
      "\n",
      "Accuracy score 0.8132059079061685 \n",
      "\n",
      "Precision 0.6607929515418502 \n",
      "\n",
      "Recall 0.8310249307479224 \n",
      "\n",
      "F1 score 0.7361963190184049 \n",
      "\n",
      "*****************************************************************************************\n",
      "\n",
      "Selected features [43, 19, 18, 23, 1, 36, 35]\n",
      "=== Training estimator # 1 with 7 features\n",
      "===> Done training estimator # 1 in 15.72871994972229 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [40, 25, 6, 36, 47, 24, 44]\n",
      "=== Training estimator # 2 with 7 features\n",
      "===> Done training estimator # 2 in 12.239742040634155 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [4, 18, 10, 23, 40, 3, 28]\n",
      "=== Training estimator # 3 with 7 features\n",
      "===> Done training estimator # 3 in 15.024028539657593 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [23, 44, 4, 22, 27, 10, 33]\n",
      "=== Training estimator # 4 with 7 features\n",
      "===> Done training estimator # 4 in 13.630110263824463 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [22, 10, 26, 34, 20, 33, 43]\n",
      "=== Training estimator # 5 with 7 features\n",
      "===> Done training estimator # 5 in 11.34957218170166 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [22, 49, 3, 23, 45, 19, 31]\n",
      "=== Training estimator # 6 with 7 features\n",
      "===> Done training estimator # 6 in 15.135310649871826 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [55, 18, 0, 12, 34, 14, 26]\n",
      "=== Training estimator # 7 with 7 features\n",
      "===> Done training estimator # 7 in 13.429870367050171 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [30, 33, 19, 52, 9, 5, 26]\n",
      "=== Training estimator # 8 with 7 features\n",
      "===> Done training estimator # 8 in 11.059550523757935 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [32, 41, 47, 14, 6, 37, 40]\n",
      "=== Training estimator # 9 with 7 features\n",
      "===> Done training estimator # 9 in 7.33066987991333 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [48, 45, 53, 15, 23, 9, 25]\n",
      "=== Training estimator # 10 with 7 features\n",
      "===> Done training estimator # 10 in 14.308706521987915 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [10, 27, 44, 13, 26, 42, 52]\n",
      "=== Training estimator # 11 with 7 features\n",
      "===> Done training estimator # 11 in 12.5688316822052 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [21, 14, 5, 1, 53, 32, 33]\n",
      "=== Training estimator # 12 with 7 features\n",
      "===> Done training estimator # 12 in 8.897071361541748 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [36, 1, 37, 45, 8, 25, 44]\n",
      "=== Training estimator # 13 with 7 features\n",
      "===> Done training estimator # 13 in 10.821788311004639 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [38, 55, 28, 24, 31, 10, 12]\n",
      "=== Training estimator # 14 with 7 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Done training estimator # 14 in 10.00845718383789 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [48, 7, 50, 54, 0, 8, 4]\n",
      "=== Training estimator # 15 with 7 features\n",
      "===> Done training estimator # 15 in 25.42400312423706 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [12, 6, 25, 17, 26, 29, 23]\n",
      "=== Training estimator # 16 with 7 features\n",
      "===> Done training estimator # 16 in 12.363424301147461 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [11, 48, 47, 30, 23, 5, 4]\n",
      "=== Training estimator # 17 with 7 features\n",
      "===> Done training estimator # 17 in 14.610034942626953 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [42, 31, 21, 17, 55, 15, 39]\n",
      "=== Training estimator # 18 with 7 features\n",
      "===> Done training estimator # 18 in 9.711392879486084 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [27, 31, 44, 54, 10, 48, 55]\n",
      "=== Training estimator # 19 with 7 features\n",
      "===> Done training estimator # 19 in 20.466115474700928 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [40, 14, 39, 37, 26, 18, 34]\n",
      "=== Training estimator # 20 with 7 features\n",
      "===> Done training estimator # 20 in 10.886141777038574 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [36, 24, 46, 35, 54, 22, 3]\n",
      "=== Training estimator # 21 with 7 features\n",
      "===> Done training estimator # 21 in 21.037920713424683 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [29, 28, 19, 46, 47, 54, 16]\n",
      "=== Training estimator # 22 with 7 features\n",
      "===> Done training estimator # 22 in 20.699535608291626 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [7, 23, 18, 28, 20, 45, 0]\n",
      "=== Training estimator # 23 with 7 features\n",
      "===> Done training estimator # 23 in 17.395231008529663 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [5, 44, 51, 9, 26, 2, 47]\n",
      "=== Training estimator # 24 with 7 features\n",
      "===> Done training estimator # 24 in 17.630584239959717 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [35, 15, 37, 40, 19, 16, 11]\n",
      "=== Training estimator # 25 with 7 features\n",
      "===> Done training estimator # 25 in 11.52324891090393 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [27, 46, 45, 32, 41, 34, 47]\n",
      "=== Training estimator # 26 with 7 features\n",
      "===> Done training estimator # 26 in 7.472557306289673 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [45, 32, 15, 8, 35, 29, 22]\n",
      "=== Training estimator # 27 with 7 features\n",
      "===> Done training estimator # 27 in 10.812248945236206 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [18, 52, 21, 20, 47, 14, 27]\n",
      "=== Training estimator # 28 with 7 features\n",
      "===> Done training estimator # 28 in 17.757917642593384 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [56, 34, 35, 49, 4, 3, 11]\n",
      "=== Training estimator # 29 with 7 features\n",
      "===> Done training estimator # 29 in 20.75535225868225 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [36, 34, 19, 22, 46, 51, 25]\n",
      "=== Training estimator # 30 with 7 features\n",
      "===> Done training estimator # 30 in 12.9110848903656 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [34, 7, 38, 28, 0, 31, 36]\n",
      "=== Training estimator # 31 with 7 features\n",
      "===> Done training estimator # 31 in 8.390328168869019 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [21, 13, 49, 43, 28, 17, 20]\n",
      "=== Training estimator # 32 with 7 features\n",
      "===> Done training estimator # 32 in 16.422614574432373 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [34, 18, 31, 49, 29, 7, 38]\n",
      "=== Training estimator # 33 with 7 features\n",
      "===> Done training estimator # 33 in 16.68411421775818 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [22, 27, 7, 43, 36, 40, 23]\n",
      "=== Training estimator # 34 with 7 features\n",
      "===> Done training estimator # 34 in 10.375378608703613 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [44, 46, 36, 31, 41, 45, 24]\n",
      "=== Training estimator # 35 with 7 features\n",
      "===> Done training estimator # 35 in 9.24448847770691 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [20, 10, 32, 35, 44, 49, 8]\n",
      "=== Training estimator # 36 with 7 features\n",
      "===> Done training estimator # 36 in 19.68411660194397 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [23, 18, 11, 45, 7, 51, 1]\n",
      "=== Training estimator # 37 with 7 features\n",
      "===> Done training estimator # 37 in 22.749094247817993 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [24, 41, 1, 8, 47, 0, 20]\n",
      "=== Training estimator # 38 with 7 features\n",
      "===> Done training estimator # 38 in 12.318150043487549 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [29, 26, 40, 30, 42, 52, 55]\n",
      "=== Training estimator # 39 with 7 features\n",
      "===> Done training estimator # 39 in 9.87845253944397 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [43, 13, 16, 38, 8, 55, 41]\n",
      "=== Training estimator # 40 with 7 features\n",
      "===> Done training estimator # 40 in 8.946596384048462 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [18, 12, 5, 40, 26, 0, 42]\n",
      "=== Training estimator # 41 with 7 features\n",
      "===> Done training estimator # 41 in 13.29489779472351 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [30, 36, 52, 35, 12, 24, 34]\n",
      "=== Training estimator # 42 with 7 features\n",
      "===> Done training estimator # 42 in 11.055814743041992 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [50, 19, 24, 17, 52, 12, 35]\n",
      "=== Training estimator # 43 with 7 features\n",
      "===> Done training estimator # 43 in 13.283558130264282 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [15, 29, 38, 17, 37, 19, 12]\n",
      "=== Training estimator # 44 with 7 features\n",
      "===> Done training estimator # 44 in 10.5849928855896 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [22, 20, 42, 51, 52, 49, 10]\n",
      "=== Training estimator # 45 with 7 features\n",
      "===> Done training estimator # 45 in 27.021921396255493 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [15, 53, 8, 30, 4, 12, 6]\n",
      "=== Training estimator # 46 with 7 features\n",
      "===> Done training estimator # 46 in 12.696097373962402 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [1, 24, 40, 43, 30, 12, 38]\n",
      "=== Training estimator # 47 with 7 features\n",
      "===> Done training estimator # 47 in 7.97399115562439 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [26, 51, 36, 6, 16, 33, 12]\n",
      "=== Training estimator # 48 with 7 features\n",
      "===> Done training estimator # 48 in 13.482784509658813 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [10, 29, 47, 17, 31, 28, 41]\n",
      "=== Training estimator # 49 with 7 features\n",
      "===> Done training estimator # 49 in 8.341303825378418 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [23, 6, 0, 51, 14, 25, 39]\n",
      "=== Training estimator # 50 with 7 features\n",
      "===> Done training estimator # 50 in 13.823213577270508 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [10, 9, 2, 22, 26, 37, 48]\n",
      "=== Training estimator # 51 with 7 features\n",
      "===> Done training estimator # 51 in 11.625408172607422 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [41, 40, 37, 13, 5, 0, 9]\n",
      "=== Training estimator # 52 with 7 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Done training estimator # 52 in 7.626392602920532 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [9, 7, 34, 4, 52, 20, 25]\n",
      "=== Training estimator # 53 with 7 features\n",
      "===> Done training estimator # 53 in 16.185197114944458 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [27, 12, 46, 36, 55, 8, 10]\n",
      "=== Training estimator # 54 with 7 features\n",
      "===> Done training estimator # 54 in 8.752629518508911 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [40, 35, 47, 11, 46, 50, 44]\n",
      "=== Training estimator # 55 with 7 features\n",
      "===> Done training estimator # 55 in 10.007098197937012 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [47, 40, 20, 51, 13, 4, 45]\n",
      "=== Training estimator # 56 with 7 features\n",
      "===> Done training estimator # 56 in 18.036325693130493 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [18, 31, 35, 28, 47, 56, 1]\n",
      "=== Training estimator # 57 with 7 features\n",
      "===> Done training estimator # 57 in 17.906211614608765 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [44, 11, 4, 19, 27, 49, 1]\n",
      "=== Training estimator # 58 with 7 features\n",
      "===> Done training estimator # 58 in 20.944998502731323 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [32, 56, 25, 22, 23, 19, 45]\n",
      "=== Training estimator # 59 with 7 features\n",
      "===> Done training estimator # 59 in 19.89297866821289 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [11, 40, 5, 1, 24, 10, 41]\n",
      "=== Training estimator # 60 with 7 features\n",
      "===> Done training estimator # 60 in 13.359777212142944 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [8, 18, 46, 39, 38, 50, 43]\n",
      "=== Training estimator # 61 with 7 features\n",
      "===> Done training estimator # 61 in 13.990784645080566 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [17, 11, 14, 3, 7, 42, 50]\n",
      "=== Training estimator # 62 with 7 features\n",
      "===> Done training estimator # 62 in 11.493059396743774 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [49, 38, 46, 14, 10, 8, 44]\n",
      "=== Training estimator # 63 with 7 features\n",
      "===> Done training estimator # 63 in 17.27798581123352 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [43, 49, 46, 52, 7, 53, 24]\n",
      "=== Training estimator # 64 with 7 features\n",
      "===> Done training estimator # 64 in 16.58533501625061 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [27, 30, 32, 15, 38, 41, 44]\n",
      "=== Training estimator # 65 with 7 features\n",
      "===> Done training estimator # 65 in 10.788782358169556 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [39, 44, 56, 34, 41, 26, 36]\n",
      "=== Training estimator # 66 with 7 features\n",
      "===> Done training estimator # 66 in 15.125061273574829 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [4, 5, 8, 51, 21, 13, 2]\n",
      "=== Training estimator # 67 with 7 features\n",
      "===> Done training estimator # 67 in 14.780631303787231 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [4, 41, 31, 16, 34, 36, 48]\n",
      "=== Training estimator # 68 with 7 features\n",
      "===> Done training estimator # 68 in 10.804073095321655 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [38, 3, 48, 7, 51, 24, 42]\n",
      "=== Training estimator # 69 with 7 features\n",
      "===> Done training estimator # 69 in 14.517974138259888 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [25, 22, 5, 55, 8, 53, 47]\n",
      "=== Training estimator # 70 with 7 features\n",
      "===> Done training estimator # 70 in 10.29846715927124 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [45, 31, 47, 14, 8, 13, 41]\n",
      "=== Training estimator # 71 with 7 features\n",
      "===> Done training estimator # 71 in 7.777187347412109 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [23, 19, 33, 37, 3, 46, 5]\n",
      "=== Training estimator # 72 with 7 features\n",
      "===> Done training estimator # 72 in 4.988219499588013 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [16, 42, 22, 0, 29, 6, 43]\n",
      "=== Training estimator # 73 with 7 features\n",
      "===> Done training estimator # 73 in 10.758764505386353 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [37, 35, 49, 43, 32, 38, 18]\n",
      "=== Training estimator # 74 with 7 features\n",
      "===> Done training estimator # 74 in 17.35578203201294 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [42, 21, 14, 9, 40, 1, 44]\n",
      "=== Training estimator # 75 with 7 features\n",
      "===> Done training estimator # 75 in 10.184919118881226 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [39, 26, 45, 2, 40, 11, 43]\n",
      "=== Training estimator # 76 with 7 features\n",
      "===> Done training estimator # 76 in 11.423089265823364 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [55, 16, 46, 33, 27, 47, 11]\n",
      "=== Training estimator # 77 with 7 features\n",
      "===> Done training estimator # 77 in 9.547192573547363 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [12, 39, 22, 21, 11, 3, 4]\n",
      "=== Training estimator # 78 with 7 features\n",
      "===> Done training estimator # 78 in 12.217929124832153 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [13, 53, 0, 16, 18, 10, 21]\n",
      "=== Training estimator # 79 with 7 features\n",
      "===> Done training estimator # 79 in 13.863598823547363 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [34, 32, 24, 50, 13, 8, 47]\n",
      "=== Training estimator # 80 with 7 features\n",
      "===> Done training estimator # 80 in 8.847147703170776 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [8, 30, 27, 34, 36, 43, 14]\n",
      "=== Training estimator # 81 with 7 features\n",
      "===> Done training estimator # 81 in 8.443853855133057 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [25, 34, 10, 52, 17, 35, 9]\n",
      "=== Training estimator # 82 with 7 features\n",
      "===> Done training estimator # 82 in 13.554348945617676 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [5, 22, 56, 16, 41, 53, 25]\n",
      "=== Training estimator # 83 with 7 features\n",
      "===> Done training estimator # 83 in 17.95344638824463 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [27, 34, 41, 16, 15, 17, 31]\n",
      "=== Training estimator # 84 with 7 features\n",
      "===> Done training estimator # 84 in 10.470598220825195 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [3, 10, 35, 42, 4, 49, 8]\n",
      "=== Training estimator # 85 with 7 features\n",
      "===> Done training estimator # 85 in 15.428638696670532 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [49, 25, 6, 29, 23, 50, 36]\n",
      "=== Training estimator # 86 with 7 features\n",
      "===> Done training estimator # 86 in 15.961726188659668 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [22, 54, 32, 45, 46, 10, 36]\n",
      "=== Training estimator # 87 with 7 features\n",
      "===> Done training estimator # 87 in 20.705164194107056 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [7, 9, 1, 5, 43, 38, 40]\n",
      "=== Training estimator # 88 with 7 features\n",
      "===> Done training estimator # 88 in 9.612854242324829 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [15, 48, 51, 53, 26, 5, 28]\n",
      "=== Training estimator # 89 with 7 features\n",
      "===> Done training estimator # 89 in 16.503971099853516 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [36, 17, 26, 0, 38, 40, 55]\n",
      "=== Training estimator # 90 with 7 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Done training estimator # 90 in 10.079874277114868 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [53, 47, 48, 23, 52, 27, 11]\n",
      "=== Training estimator # 91 with 7 features\n",
      "===> Done training estimator # 91 in 15.988931655883789 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [36, 3, 43, 6, 30, 29, 24]\n",
      "=== Training estimator # 92 with 7 features\n",
      "===> Done training estimator # 92 in 9.185672998428345 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [36, 42, 31, 52, 14, 39, 15]\n",
      "=== Training estimator # 93 with 7 features\n",
      "===> Done training estimator # 93 in 10.487852096557617 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [49, 8, 2, 12, 15, 34, 29]\n",
      "=== Training estimator # 94 with 7 features\n",
      "===> Done training estimator # 94 in 15.97676134109497 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [22, 9, 55, 40, 20, 41, 37]\n",
      "=== Training estimator # 95 with 7 features\n",
      "===> Done training estimator # 95 in 10.849788188934326 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [29, 8, 45, 6, 38, 32, 5]\n",
      "=== Training estimator # 96 with 7 features\n",
      "===> Done training estimator # 96 in 9.864895582199097 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [55, 33, 6, 7, 44, 2, 21]\n",
      "=== Training estimator # 97 with 7 features\n",
      "===> Done training estimator # 97 in 11.310919284820557 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [42, 29, 48, 30, 47, 33, 34]\n",
      "=== Training estimator # 98 with 7 features\n",
      "===> Done training estimator # 98 in 9.666271924972534 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [47, 21, 27, 18, 25, 24, 17]\n",
      "=== Training estimator # 99 with 7 features\n",
      "===> Done training estimator # 99 in 16.115492343902588 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [34, 0, 16, 3, 14, 17, 7]\n",
      "=== Training estimator # 100 with 7 features\n",
      "===> Done training estimator # 100 in 8.574560165405273 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[648 201]\n",
      " [ 49 253]] \n",
      "\n",
      "True negative: 648 , false positive: 201 , false negative: 49 ,true positive: 253 \n",
      "\n",
      "Accuracy score 0.7827975673327541 \n",
      "\n",
      "Precision 0.5572687224669604 \n",
      "\n",
      "Recall 0.8377483443708609 \n",
      "\n",
      "F1 score 0.6693121693121693 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)\n",
    "\n",
    "print(\"*****************************************************************************************\\n\")\n",
    "\n",
    "rfc = RandomForestClassifier(num_est=50, max_depth=10, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)\n",
    "\n",
    "print(\"*****************************************************************************************\\n\")\n",
    "\n",
    "rfc = RandomForestClassifier(num_est=100, max_depth=10, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[694  24]\n",
      " [  3 430]] \n",
      "\n",
      "True negative: 694 , false positive: 24 , false negative: 3 ,true positive: 430 \n",
      "\n",
      "Accuracy score 0.9765421372719374 \n",
      "\n",
      "Precision 0.947136563876652 \n",
      "\n",
      "Recall 0.9930715935334873 \n",
      "\n",
      "F1 score 0.9695603156708005 \n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Confusion matrix\n",
      " [[697  20]\n",
      " [  0 434]] \n",
      "\n",
      "True negative: 697 , false positive: 20 , false negative: 0 ,true positive: 434 \n",
      "\n",
      "Accuracy score 0.9826238053866203 \n",
      "\n",
      "Precision 0.9559471365638766 \n",
      "\n",
      "Recall 1.0 \n",
      "\n",
      "F1 score 0.9774774774774774 \n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Confusion matrix\n",
      " [[696  22]\n",
      " [  1 432]] \n",
      "\n",
      "True negative: 696 , false positive: 22 , false negative: 1 ,true positive: 432 \n",
      "\n",
      "Accuracy score 0.9800173761946134 \n",
      "\n",
      "Precision 0.9515418502202643 \n",
      "\n",
      "Recall 0.9976905311778291 \n",
      "\n",
      "F1 score 0.9740698985343856 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=10, max_features=7)\n",
    "rfc.fit(X_test, y_test)\n",
    "classfierData(rfc, X_test, y_test)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=50, max_features=7)\n",
    "rfc.fit(X_test, y_test)\n",
    "classfierData(rfc, X_test, y_test)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=100, max_features=7)\n",
    "rfc.fit(X_test, y_test)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10), n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[668  33]\n",
      " [ 29 421]] \n",
      "\n",
      "True negative: 668 , false positive: 33 , false negative: 29 ,true positive: 421 \n",
      "\n",
      "Accuracy score 0.946133796698523 \n",
      "\n",
      "Precision 0.9273127753303965 \n",
      "\n",
      "Recall 0.9355555555555556 \n",
      "\n",
      "F1 score 0.9314159292035398 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(ada, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ada = AdaBoostClassifier(LogisticRegression(), n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[653  69]\n",
      " [ 44 385]] \n",
      "\n",
      "True negative: 653 , false positive: 69 , false negative: 44 ,true positive: 385 \n",
      "\n",
      "Accuracy score 0.9018245004344049 \n",
      "\n",
      "Precision 0.8480176211453745 \n",
      "\n",
      "Recall 0.8974358974358975 \n",
      "\n",
      "F1 score 0.8720271800679501 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada.fit(X_train, y_train)\n",
    "classfierData(ada, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost classifier data for 10 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[669  35]\n",
      " [ 28 419]] \n",
      "\n",
      "True negative: 669 , false positive: 35 , false negative: 28 ,true positive: 419 \n",
      "\n",
      "Accuracy score 0.945264986967854 \n",
      "\n",
      "Precision 0.9229074889867841 \n",
      "\n",
      "Recall 0.9373601789709173 \n",
      "\n",
      "F1 score 0.93007769145394 \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "AdaBoost classifier data for 50 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[665  35]\n",
      " [ 32 419]] \n",
      "\n",
      "True negative: 665 , false positive: 35 , false negative: 32 ,true positive: 419 \n",
      "\n",
      "Accuracy score 0.9417897480451781 \n",
      "\n",
      "Precision 0.9229074889867841 \n",
      "\n",
      "Recall 0.9290465631929047 \n",
      "\n",
      "F1 score 0.9259668508287293 \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "AdaBoost classifier data for 100 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[675  32]\n",
      " [ 22 422]] \n",
      "\n",
      "True negative: 675 , false positive: 32 , false negative: 22 ,true positive: 422 \n",
      "\n",
      "Accuracy score 0.9530842745438749 \n",
      "\n",
      "Precision 0.9295154185022027 \n",
      "\n",
      "Recall 0.9504504504504504 \n",
      "\n",
      "F1 score 0.9398663697104677 \n",
      "\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_learners = [10, 50, 100]\n",
    "# use with decision tree\n",
    "for l in base_learners:\n",
    "    ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10), n_estimators=l)\n",
    "    ada.fit(X_train, y_train)\n",
    "    print(\"AdaBoost classifier data for\", l, \"number of estimators\\n\")\n",
    "    print(\"*********************************************************************\")\n",
    "    classfierData(ada, X_test, y_test)\n",
    "    print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost classifier data for 10 number of Random Forest estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[678  31]\n",
      " [ 19 423]] \n",
      "\n",
      "True negative: 678 , false positive: 31 , false negative: 19 ,true positive: 423 \n",
      "\n",
      "Accuracy score 0.9565595134665508 \n",
      "\n",
      "Precision 0.9317180616740088 \n",
      "\n",
      "Recall 0.9570135746606335 \n",
      "\n",
      "F1 score 0.9441964285714286 \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "AdaBoost classifier data for 50 number of Random Forest estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[676  32]\n",
      " [ 21 422]] \n",
      "\n",
      "True negative: 676 , false positive: 32 , false negative: 21 ,true positive: 422 \n",
      "\n",
      "Accuracy score 0.9539530842745438 \n",
      "\n",
      "Precision 0.9295154185022027 \n",
      "\n",
      "Recall 0.9525959367945824 \n",
      "\n",
      "F1 score 0.9409141583054628 \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "AdaBoost classifier data for 100 number of Random Forest estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[680  39]\n",
      " [ 17 415]] \n",
      "\n",
      "True negative: 680 , false positive: 39 , false negative: 17 ,true positive: 415 \n",
      "\n",
      "Accuracy score 0.9513466550825369 \n",
      "\n",
      "Precision 0.9140969162995595 \n",
      "\n",
      "Recall 0.9606481481481481 \n",
      "\n",
      "F1 score 0.9367945823927766 \n",
      "\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for l in base_learners:\n",
    "    ada = AdaBoostClassifier(RandomForestClassifier(n_estimators=10), n_estimators=l)\n",
    "    ada.fit(X_train, y_train)\n",
    "    print(\"AdaBoost classifier data for\", l, \"number of Random Forest estimators\\n\")\n",
    "    print(\"*********************************************************************\")\n",
    "    classfierData(ada, X_test, y_test)\n",
    "    print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "X_train = np.reshape(X_train, (60000, 784))\n",
    "X_test = np.reshape(X_test, (10000, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for FFN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will have 3 hidden layer. Each layer (except for the last one to produce result) will use relu as activation functions. After calculating neurons for each layer, Dropout Regularization will be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Keras, it is straightforward and easy to interprete to declare a feed forward neural network (dense network) with `Dense` constructor. With the first model, the hidden layer is a 500 neurons layer and the input layer is the same size as one picture: $28 \\times 28$. After that a relu activation function is being applied and a dropout regularization with 0.4 ratio is applied. Next layer is 300 neurons layer and similar relu/dropout being applied. Last layer is the classification layer with 10 neurons as 10 classes being represented and with a softmax activation function. All the three models (networks) use RMS optimizers and based on accuracy. All the metrics are reported on each run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=28*28))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "rms = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(model, epochs=20, batch=256):\n",
    "    start_time = time.time()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
    "    print('Training model...')\n",
    "    model.fit(X_train, y_train, nb_epoch=epochs, batch_size=batch,\n",
    "              validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    print(\"Training duration : {0}\".format(time.time() - start_time))\n",
    "    score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "    print(\"Network's test score [loss, accuracy]: {0}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 0.3588 - acc: 0.8897 - val_loss: 0.1488 - val_acc: 0.9526\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.1529 - acc: 0.9543 - val_loss: 0.1076 - val_acc: 0.9668\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.1148 - acc: 0.9650 - val_loss: 0.0896 - val_acc: 0.9725\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.0948 - acc: 0.9720 - val_loss: 0.0760 - val_acc: 0.9762\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.0829 - acc: 0.9749 - val_loss: 0.0732 - val_acc: 0.9777\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.0696 - acc: 0.9785 - val_loss: 0.0699 - val_acc: 0.9803\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.0627 - acc: 0.9805 - val_loss: 0.0821 - val_acc: 0.9780\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.0594 - acc: 0.9818 - val_loss: 0.0689 - val_acc: 0.9823\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.0530 - acc: 0.9837 - val_loss: 0.0706 - val_acc: 0.9807\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.0502 - acc: 0.9850 - val_loss: 0.0711 - val_acc: 0.9828\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0469 - acc: 0.9852 - val_loss: 0.0732 - val_acc: 0.9823\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0436 - acc: 0.9866 - val_loss: 0.0710 - val_acc: 0.9834\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0446 - acc: 0.9868 - val_loss: 0.0778 - val_acc: 0.9815\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0407 - acc: 0.9877 - val_loss: 0.0785 - val_acc: 0.9836\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0397 - acc: 0.9880 - val_loss: 0.0742 - val_acc: 0.9844\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0360 - acc: 0.9895 - val_loss: 0.0726 - val_acc: 0.9845\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0351 - acc: 0.9892 - val_loss: 0.0721 - val_acc: 0.9836\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0344 - acc: 0.9898 - val_loss: 0.0799 - val_acc: 0.9832\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0310 - acc: 0.9907 - val_loss: 0.0834 - val_acc: 0.9835\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0315 - acc: 0.9908 - val_loss: 0.0751 - val_acc: 0.9845\n",
      "Training duration : 42.93675208091736\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "Network's test score [loss, accuracy]: [0.0750931824285787, 0.9845]\n"
     ]
    }
   ],
   "source": [
    "run_network(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network is a lot simpler with only 1 output layer of 10 neurons and with a softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=28*28))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.7553 - acc: 0.8183 - val_loss: 0.3999 - val_acc: 0.8960\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.3688 - acc: 0.8989 - val_loss: 0.3221 - val_acc: 0.9115\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.3225 - acc: 0.9103 - val_loss: 0.3008 - val_acc: 0.9162\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.3028 - acc: 0.9156 - val_loss: 0.2905 - val_acc: 0.9183\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.2915 - acc: 0.9190 - val_loss: 0.2817 - val_acc: 0.9218\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.2840 - acc: 0.9209 - val_loss: 0.2773 - val_acc: 0.9231\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.2782 - acc: 0.9220 - val_loss: 0.2731 - val_acc: 0.9233\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.2738 - acc: 0.9232 - val_loss: 0.2695 - val_acc: 0.9241\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.2706 - acc: 0.9243 - val_loss: 0.2697 - val_acc: 0.9246\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.2674 - acc: 0.9254 - val_loss: 0.2688 - val_acc: 0.9253\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.2650 - acc: 0.9265 - val_loss: 0.2669 - val_acc: 0.9261\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2629 - acc: 0.9272 - val_loss: 0.2659 - val_acc: 0.9273\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2611 - acc: 0.9275 - val_loss: 0.2678 - val_acc: 0.9265\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2593 - acc: 0.9281 - val_loss: 0.2664 - val_acc: 0.9264\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2582 - acc: 0.9286 - val_loss: 0.2650 - val_acc: 0.9272\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2567 - acc: 0.9289 - val_loss: 0.2645 - val_acc: 0.9270\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2552 - acc: 0.9300 - val_loss: 0.2652 - val_acc: 0.9259\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2544 - acc: 0.9302 - val_loss: 0.2633 - val_acc: 0.9274\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2533 - acc: 0.9306 - val_loss: 0.2665 - val_acc: 0.9268\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2523 - acc: 0.9312 - val_loss: 0.2655 - val_acc: 0.9268\n",
      "Training duration : 6.168358325958252\n",
      "10000/10000 [==============================] - 0s 14us/step\n",
      "Network's test score [loss, accuracy]: [0.265460667720437, 0.9268]\n"
     ]
    }
   ],
   "source": [
    "run_network(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This FFN is a little bit more complicated than the second one with the first layer as a 300 neurons layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=28*28))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3398 - acc: 0.9065 - val_loss: 0.1884 - val_acc: 0.9442\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.1531 - acc: 0.9551 - val_loss: 0.1243 - val_acc: 0.9628\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.1046 - acc: 0.9692 - val_loss: 0.0931 - val_acc: 0.9723\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.0785 - acc: 0.9769 - val_loss: 0.0852 - val_acc: 0.9739\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.0614 - acc: 0.9822 - val_loss: 0.0795 - val_acc: 0.9753\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.0494 - acc: 0.9854 - val_loss: 0.0706 - val_acc: 0.9770\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.0405 - acc: 0.9886 - val_loss: 0.0689 - val_acc: 0.9784\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.0338 - acc: 0.9905 - val_loss: 0.0843 - val_acc: 0.9739\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.0276 - acc: 0.9923 - val_loss: 0.0723 - val_acc: 0.9781\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.0223 - acc: 0.9941 - val_loss: 0.0669 - val_acc: 0.9817\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.0189 - acc: 0.9951 - val_loss: 0.0659 - val_acc: 0.9799\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.0154 - acc: 0.9962 - val_loss: 0.0677 - val_acc: 0.9796\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.0127 - acc: 0.9971 - val_loss: 0.0735 - val_acc: 0.9787\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0738 - val_acc: 0.9787\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.0085 - acc: 0.9984 - val_loss: 0.0666 - val_acc: 0.9818\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.0069 - acc: 0.9985 - val_loss: 0.0726 - val_acc: 0.9805\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.0058 - acc: 0.9990 - val_loss: 0.0728 - val_acc: 0.9811\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0782 - val_acc: 0.9799\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.0039 - acc: 0.9992 - val_loss: 0.0736 - val_acc: 0.9811\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0791 - val_acc: 0.9810\n",
      "Training duration : 19.682542324066162\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "Network's test score [loss, accuracy]: [0.07908815086199916, 0.981]\n"
     ]
    }
   ],
   "source": [
    "run_network(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Convolutional Neural Network, we will not flatten the $28 \\times 28$ image into a $781 \\times 1$ vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to normal FFN, Conv net in keras is straightforward to declare and also easy to interprete from the code. For example, this NN has the first layer as a 64 neurons with a $2 \\times 2$ filter. The input is the same size as the image $28 \\times 28 \\times 1$ and with relu activation. The next maxpooling layer is having a $2\\times 2$ pool size (pooling windows). Similarly, the next Conv Net layer is being declared. Lastly, the output layer has 10 neurons and with a softmax activation to classify the labels.\n",
    "\n",
    "The next two layers are having the same description so I would not explained further and Keras does a great job at having a declarative API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "convMod = Sequential()\n",
    "\n",
    "convMod.add(Conv2D(64, (2, 2), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "convMod.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "convMod.add(Conv2D(64, (2, 2), activation = 'relu'))\n",
    "convMod.add(MaxPooling2D(pool_size = (1, 1)))\n",
    "convMod.add(Dropout(0.2))\n",
    "\n",
    "convMod.add(Flatten())\n",
    "\n",
    "convMod.add(Dense(units = 128, activation='relu'))\n",
    "convMod.add(Dropout(0.5))\n",
    "convMod.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 51s 848us/step - loss: 0.1996 - acc: 0.9399\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 50s 836us/step - loss: 0.0916 - acc: 0.9737\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 50s 839us/step - loss: 0.0795 - acc: 0.9768\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 50s 833us/step - loss: 0.0784 - acc: 0.9779\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 50s 833us/step - loss: 0.0836 - acc: 0.9768\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.0816 - acc: 0.9776\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 51s 847us/step - loss: 0.0828 - acc: 0.9768\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 57s 943us/step - loss: 0.0868 - acc: 0.9768\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 57s 944us/step - loss: 0.0908 - acc: 0.9764\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 56s 927us/step - loss: 0.0927 - acc: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d140b0198>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convMod.compile(optimizer=rms, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "convMod.fit(x_train, y_train,epochs=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 213us/step\n",
      "[0.055363797660581075, 0.9844]\n"
     ]
    }
   ],
   "source": [
    "print(convMod.evaluate(x_test, y_test, batch_size=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "convMod = Sequential()\n",
    "\n",
    "convMod.add(Conv2D(64, (4, 4), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "convMod.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "convMod.add(Dropout(0.2))\n",
    "convMod.add(Flatten())\n",
    "convMod.add(Dense(units = 128, activation='relu'))\n",
    "convMod.add(Dropout(0.5))\n",
    "convMod.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 41s 684us/step - loss: 0.0892 - acc: 0.9771\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 40s 664us/step - loss: 0.0934 - acc: 0.9761\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 42s 707us/step - loss: 0.0959 - acc: 0.9754\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 38s 631us/step - loss: 0.0961 - acc: 0.9763\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 38s 625us/step - loss: 0.0994 - acc: 0.9755\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 41s 679us/step - loss: 0.1000 - acc: 0.9749\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 39s 658us/step - loss: 0.1032 - acc: 0.9747\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 38s 625us/step - loss: 0.1093 - acc: 0.9738\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 38s 633us/step - loss: 0.1097 - acc: 0.9731\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 38s 626us/step - loss: 0.1113 - acc: 0.9734\n",
      "10000/10000 [==============================] - 2s 184us/step\n",
      "[0.08472569277707576, 0.9783]\n"
     ]
    }
   ],
   "source": [
    "convMod.compile(optimizer=rms, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "convMod.fit(x_train, y_train,epochs=10, verbose = 1)\n",
    "print(convMod.evaluate(x_test, y_test, batch_size=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "convMod = Sequential()\n",
    "\n",
    "convMod.add(Conv2D(64, (2, 2), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "convMod.add(MaxPooling2D(pool_size = (1, 1)))\n",
    "convMod.add(Dropout(0.4))\n",
    "convMod.add(Flatten())\n",
    "convMod.add(Dense(units = 32, activation='relu'))\n",
    "convMod.add(Dropout(0.8))\n",
    "convMod.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 39s 657us/step - loss: 0.1990 - acc: 0.9405\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 39s 653us/step - loss: 0.0928 - acc: 0.9736\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 39s 651us/step - loss: 0.0814 - acc: 0.9771\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 39s 649us/step - loss: 0.0791 - acc: 0.9776\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 39s 650us/step - loss: 0.0773 - acc: 0.9779\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 39s 651us/step - loss: 0.0773 - acc: 0.9782\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 39s 650us/step - loss: 0.0783 - acc: 0.9787\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 39s 650us/step - loss: 0.0816 - acc: 0.9781\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 39s 650us/step - loss: 0.0820 - acc: 0.9782\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 39s 646us/step - loss: 0.0842 - acc: 0.9777\n",
      "10000/10000 [==============================] - 2s 199us/step\n",
      "[0.09358933336165728, 0.9786]\n"
     ]
    }
   ],
   "source": [
    "convMod.compile(optimizer=rms, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "convMod.fit(x_train, y_train,epochs=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 190us/step\n",
      "[0.5539265819072723, 0.9153]\n"
     ]
    }
   ],
   "source": [
    "print(convMod.evaluate(x_test, y_test, batch_size=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this specific problem, I think normal feed forward neural network did fine with faster training time and overall accuracy is 98% with just 10 epochs. Conv Net trained longer with this simple images dataset and might be an overkill. I think for a complex dataset, Conv Net will be more useful as it learns the image by applying different filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
