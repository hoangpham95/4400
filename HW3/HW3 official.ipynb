{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "matrix = []\n",
    "\n",
    "with open(\"spambase.data\", \"r\") as raw_data:\n",
    "    for raw_line in raw_data:\n",
    "        line = [float(x) for x in raw_line.split(\",\")]\n",
    "        matrix.append(line)\n",
    "\n",
    "data = pd.DataFrame(matrix)\n",
    "row, col = data.shape\n",
    "X, y = data.iloc[:,:col - 1], data[col - 1]\n",
    "# y = y.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest Classifier on existing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfierData(clf, X, y):\n",
    "    test_data = clf.predict(X)\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(test_data, y), \"\\n\")\n",
    "    tn, fp, fn, tp = confusion_matrix(test_data, y).ravel()\n",
    "    print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "    print(\"Accuracy score\", accuracy_score(test_data, y), \"\\n\")\n",
    "    print(\"Precision\", precision_score(test_data, y), \"\\n\")\n",
    "    print(\"Recall\", recall_score(test_data, y), \"\\n\")\n",
    "    print(\"F1 score\", f1_score(test_data, y), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[2089    1]\n",
      " [   2 1358]] \n",
      "\n",
      "True negative: 2089 , false positive: 1 , false negative: 2 ,true positive: 1358 \n",
      "\n",
      "Accuracy score 0.9991304347826087 \n",
      "\n",
      "Precision 0.9992641648270787 \n",
      "\n",
      "Recall 0.9985294117647059 \n",
      "\n",
      "F1 score 0.9988966531813166 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[681  46]\n",
      " [ 16 408]] \n",
      "\n",
      "True negative: 681 , false positive: 46 , false negative: 16 ,true positive: 408 \n",
      "\n",
      "Accuracy score 0.946133796698523 \n",
      "\n",
      "Precision 0.8986784140969163 \n",
      "\n",
      "Recall 0.9622641509433962 \n",
      "\n",
      "F1 score 0.9293849658314352 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing own Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicate class acts as the splitting question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    def match(self, example, pp=False):\n",
    "        if pp:\n",
    "            print(\"Match on column\", self.column)\n",
    "        val = example[self.column]\n",
    "        if Util.is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Question: column {}, value {}'.format(self.column, self.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility functions that being reused a lot in the implementation of random forest. In this implementation, I used gini impurity instead of entropy since `log` function would arguably take longer to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Util:\n",
    "    @staticmethod\n",
    "    def label_count(labels):\n",
    "        count = {}\n",
    "        for r in labels:\n",
    "            if r not in count:\n",
    "                count[r] = 0\n",
    "            count[r] += 1\n",
    "        return count\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_numeric(val):\n",
    "        return isinstance(val, int) or isinstance(val, float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition(X, y, pred):\n",
    "        true_X, false_X, true_y, false_y = [], [], [], []\n",
    "        \n",
    "        for x_inst, y_inst in zip(X, y):\n",
    "            if pred.match(x_inst):\n",
    "                true_X.append(x_inst)\n",
    "                true_y.append(y_inst)\n",
    "            else:\n",
    "                false_X.append(x_inst)\n",
    "                false_y.append(y_inst)\n",
    "        return true_X, true_y, false_X, false_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_impur(labels):\n",
    "        \"\"\"\n",
    "        Gini impurity\n",
    "        \"\"\"\n",
    "        counts = Util.label_count(labels)\n",
    "        total = 0\n",
    "        for lbl in counts:\n",
    "            prob_of_lbl = float(counts[lbl]) / len(labels)\n",
    "            total += (prob_of_lbl * prob_of_lbl)\n",
    "        return 1 - total\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_gain(leftLbl, rightLbl, curr_uncertainty):\n",
    "        \"\"\"\n",
    "        Calculating information gain\n",
    "        \"\"\"\n",
    "        p = float (len(leftLbl)) / (len(leftLbl) + len(rightLbl))\n",
    "        return curr_uncertainty - p * Util.gini_impur(leftLbl) - (1 - p) * Util.gini_impur(rightLbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, y, depth=0):\n",
    "        self.depth = depth\n",
    "        pred = Util.label_count(y)\n",
    "        for l in pred:\n",
    "            pred[l] = pred[l] / len(y)\n",
    "        self.predictions = pred\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return True\n",
    "\n",
    "class DecTreeNode:\n",
    "    def __init__(self, pred, true_branch, false_branch, depth=0):\n",
    "        self.depth = depth\n",
    "        self.pred = pred\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecTreeClassifier:\n",
    "    def __init__(self, max_depth=10):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def findBestSplit(self, X, y, pp=False):\n",
    "        start = time.time()\n",
    "        best_gain = 0  \n",
    "        best_pred = None\n",
    "        current_uncert = Util.gini_impur(y)\n",
    "        \n",
    "        for col in self.selected_features:\n",
    "            vals = set([row[col] for row in X]) # different values in column\n",
    "            \n",
    "            for v in vals:\n",
    "                pred = Predicate(col, v)\n",
    "                true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "                \n",
    "                if len(true_X) == 0 or len(false_X) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = Util.info_gain(true_y, false_y, current_uncert)\n",
    "                \n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_pred = gain, pred\n",
    "        if pp:\n",
    "            print(\"Find best split size\", np.array(X).shape, \"took\", time.time() - start)\n",
    "        return best_gain, best_pred\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        gain, pred = self.findBestSplit(X, y)\n",
    "        if gain == 0 or depth >= self.max_depth:\n",
    "            return Leaf(y, depth)\n",
    "        true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "        \n",
    "        true_branch = self.build_tree(true_X, true_y, depth + 1)\n",
    "        false_branch = self.build_tree(false_X, false_y, depth + 1)\n",
    "        \n",
    "        return DecTreeNode(pred, true_branch, false_branch)\n",
    "    \n",
    "    def predict_by_tree(self, tree, X_inst):\n",
    "        if tree.isLeaf():\n",
    "            return tree.predictions\n",
    "        elif tree.pred.match(X_inst, pp=False):\n",
    "            return self.predict_by_tree(tree.true_branch, X_inst)\n",
    "        else:\n",
    "            return self.predict_by_tree(tree.false_branch, X_inst)\n",
    "    \n",
    "    def fit(self, X, y, selected_features=None):\n",
    "        if selected_features is None:\n",
    "            self.selected_features = X.columns\n",
    "        else:\n",
    "            self.selected_features = selected_features\n",
    "            \n",
    "        self.tree = self.build_tree(X.values, y.values) \n",
    "    \n",
    "    def predict_inst(self, X_inst):\n",
    "        pred = self.predict_by_tree(self.tree, np.array(X_inst))\n",
    "        max_arg, max_prob = None, 0\n",
    "        for l in pred:\n",
    "            if pred[l] > max_prob:\n",
    "                max_arg = l\n",
    "            max_prob = max(max_prob, pred[l])\n",
    "        return max_arg\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for idx, r in X.iterrows():\n",
    "            y.append(self.predict_inst(r))\n",
    "        return pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier take 269.33306765556335 seconds to build tree\n"
     ]
    }
   ],
   "source": [
    "# Training decision tree\n",
    "decTreeClf = DecTreeClassifier(max_depth=10)\n",
    "start = time.time()\n",
    "decTreeClf.fit(X_train, y_train)\n",
    "print(\"Decision tree classifier take\", time.time() - start, \"seconds to build tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to build a full tree with depth 10, it took me 247 seconds (~4 minutes). Having max depth helps us limit the training time and also avoid overfitting on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[663  66]\n",
      " [ 34 388]] \n",
      "\n",
      "True negative: 663 , false positive: 66 , false negative: 34 ,true positive: 388 \n",
      "\n",
      "Accuracy score 0.9131190269331017 \n",
      "\n",
      "Precision 0.8546255506607929 \n",
      "\n",
      "Recall 0.919431279620853 \n",
      "\n",
      "F1 score 0.8858447488584474 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(decTreeClf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[668  63]\n",
      " [ 29 391]] \n",
      "\n",
      "True negative: 668 , false positive: 63 , false negative: 29 ,true positive: 391 \n",
      "\n",
      "Accuracy score 0.9200695047784535 \n",
      "\n",
      "Precision 0.8612334801762115 \n",
      "\n",
      "Recall 0.930952380952381 \n",
      "\n",
      "F1 score 0.8947368421052633 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dcf = DecisionTreeClassifier(max_depth=10)\n",
    "dcf.fit(X_train, y_train)\n",
    "classfierData(dcf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, my implementation of Decision Tree Classifier gains approximately the same result as sklearn's Decision Tree Classifier. Now we can implement random forest classifier after decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import random\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, num_est=10, max_depth=5, num_attrs=5):\n",
    "        self.num_est = num_est\n",
    "        self.max_depth = max_depth\n",
    "        self.forest = []\n",
    "        self.num_attrs = num_attrs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Bagging\n",
    "        for i in range(self.num_est):\n",
    "            shape = len(X.columns)\n",
    "            \n",
    "            selected_features = random.sample(range(0, shape), self.num_attrs)\n",
    "            X_samp, y_samp = resample(X, y, replace=True)\n",
    "            clf = DecTreeClassifier(max_depth=self.max_depth)\n",
    "            print(\"Selected features\", selected_features)\n",
    "            start = time.time()\n",
    "            print(\"=== Training estimator #\", i + 1, \"with\", len(selected_features),\"features\")\n",
    "            clf.fit(X_samp, y_samp, selected_features=selected_features)\n",
    "            print(\"===> Done training estimator #\", i + 1, \"in\", time.time() - start, \"seconds\")\n",
    "            self.forest.append(clf)\n",
    "            print(\"--------------------------------------------------------------\\n\")\n",
    "            \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for idx, x in X.iterrows():\n",
    "            labels = {}\n",
    "            for clf in self.forest:\n",
    "                l = clf.predict_inst(x)\n",
    "                if l not in labels:\n",
    "                    labels[l] = 0\n",
    "                labels[l] += 1\n",
    "            for l in labels:\n",
    "                if labels[l] >= 0.5:\n",
    "                    result.append(l)\n",
    "                    break\n",
    "        return pd.DataFrame(result)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing random forest on $\\sqrt{d}$ attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features [6, 44, 10, 35, 12, 28, 43]\n",
      "=== Training estimator # 1 with 7 features\n",
      "===> Done training estimator # 1 in 12.335493326187134 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [37, 16, 14, 31, 49, 0, 5]\n",
      "=== Training estimator # 2 with 7 features\n",
      "===> Done training estimator # 2 in 13.729286909103394 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [27, 16, 5, 6, 12, 24, 52]\n",
      "=== Training estimator # 3 with 7 features\n",
      "===> Done training estimator # 3 in 13.08350419998169 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [48, 39, 22, 33, 23, 3, 43]\n",
      "=== Training estimator # 4 with 7 features\n",
      "===> Done training estimator # 4 in 9.32597804069519 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [45, 48, 4, 50, 23, 34, 14]\n",
      "=== Training estimator # 5 with 7 features\n",
      "===> Done training estimator # 5 in 12.284714937210083 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [16, 47, 4, 26, 1, 55, 7]\n",
      "=== Training estimator # 6 with 7 features\n",
      "===> Done training estimator # 6 in 11.723254919052124 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [40, 17, 22, 47, 12, 45, 6]\n",
      "=== Training estimator # 7 with 7 features\n",
      "===> Done training estimator # 7 in 9.617105960845947 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [8, 27, 48, 20, 19, 17, 34]\n",
      "=== Training estimator # 8 with 7 features\n",
      "===> Done training estimator # 8 in 15.14012360572815 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [19, 4, 54, 29, 56, 18, 39]\n",
      "=== Training estimator # 9 with 7 features\n",
      "===> Done training estimator # 9 in 32.41896438598633 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Selected features [2, 35, 6, 42, 12, 49, 55]\n",
      "=== Training estimator # 10 with 7 features\n",
      "===> Done training estimator # 10 in 15.657276630401611 seconds\n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[661 207]\n",
      " [ 36 247]] \n",
      "\n",
      "True negative: 661 , false positive: 207 , false negative: 36 ,true positive: 247 \n",
      "\n",
      "Accuracy score 0.788879235447437 \n",
      "\n",
      "Precision 0.5440528634361234 \n",
      "\n",
      "Recall 0.872791519434629 \n",
      "\n",
      "F1 score 0.6702849389416554 \n",
      "\n",
      "Confusion matrix\n",
      " [[2015  597]\n",
      " [  76  762]] \n",
      "\n",
      "True negative: 2015 , false positive: 597 , false negative: 76 ,true positive: 762 \n",
      "\n",
      "Accuracy score 0.8049275362318841 \n",
      "\n",
      "Precision 0.5607064017660044 \n",
      "\n",
      "Recall 0.9093078758949881 \n",
      "\n",
      "F1 score 0.6936731907146109 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(rfc, X_test, y_test)\n",
    "classfierData(rfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest on all attributes with 10 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training estimator # 1 with features [36, 11, 9, 12, 35, 32, 37, 56, 43, 22, 53, 39, 23, 20, 51, 30, 52, 14, 49, 44, 1, 31, 34, 10, 28, 8, 26, 40, 41, 2, 29, 18, 27, 50, 19, 45, 38, 25, 15, 16, 47, 3, 4, 46, 33, 6, 0, 17, 55, 7, 24, 21, 5, 42, 48, 54, 13]\n",
      "===> Done training estimator # 1 in 239.93970227241516 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with features [0, 15, 21, 48, 20, 4, 46, 33, 18, 54, 31, 8, 1, 36, 5, 16, 52, 11, 39, 26, 25, 40, 53, 41, 55, 10, 3, 32, 43, 27, 38, 45, 6, 49, 28, 22, 47, 2, 37, 50, 42, 12, 14, 30, 56, 23, 9, 7, 35, 13, 17, 29, 44, 24, 19, 34, 51]\n",
      "===> Done training estimator # 2 in 247.90983271598816 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with features [46, 23, 48, 8, 55, 10, 56, 16, 4, 2, 9, 36, 5, 28, 26, 54, 20, 39, 11, 18, 51, 30, 41, 13, 17, 19, 22, 29, 49, 35, 1, 45, 3, 42, 38, 32, 7, 12, 33, 37, 34, 53, 52, 15, 0, 21, 31, 24, 14, 50, 27, 43, 47, 6, 40, 25, 44]\n",
      "===> Done training estimator # 3 in 211.30190110206604 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with features [6, 48, 22, 54, 18, 39, 23, 19, 32, 45, 53, 27, 43, 37, 36, 0, 12, 20, 29, 52, 47, 13, 9, 33, 5, 56, 16, 40, 49, 42, 44, 4, 34, 10, 14, 3, 38, 1, 7, 50, 15, 11, 24, 28, 55, 30, 51, 41, 35, 26, 17, 31, 21, 8, 46, 25, 2]\n",
      "===> Done training estimator # 4 in 199.1002550125122 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with features [16, 7, 12, 54, 23, 0, 49, 27, 6, 9, 52, 33, 13, 45, 22, 26, 5, 34, 46, 37, 38, 40, 2, 15, 1, 44, 53, 8, 17, 56, 47, 25, 28, 35, 10, 31, 50, 51, 3, 48, 41, 21, 36, 55, 18, 11, 39, 20, 19, 43, 24, 30, 4, 32, 29, 42, 14]\n",
      "===> Done training estimator # 5 in 196.6109220981598 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with features [10, 55, 28, 9, 29, 3, 31, 14, 39, 32, 24, 27, 47, 50, 48, 46, 1, 15, 49, 26, 37, 43, 22, 25, 18, 19, 4, 45, 5, 56, 16, 21, 41, 8, 42, 11, 54, 20, 0, 35, 38, 33, 51, 44, 12, 40, 7, 34, 17, 30, 6, 52, 36, 53, 23, 13, 2]\n",
      "===> Done training estimator # 6 in 196.98835849761963 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with features [27, 47, 51, 17, 38, 0, 56, 36, 49, 44, 46, 13, 28, 42, 55, 5, 29, 20, 41, 12, 35, 8, 33, 21, 6, 15, 22, 3, 53, 34, 43, 11, 39, 26, 16, 10, 14, 30, 2, 9, 52, 31, 40, 37, 4, 32, 45, 54, 48, 23, 18, 19, 25, 24, 7, 1, 50]\n",
      "===> Done training estimator # 7 in 198.19417262077332 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with features [19, 12, 16, 6, 38, 40, 49, 8, 14, 4, 55, 27, 45, 54, 56, 10, 34, 5, 7, 20, 44, 53, 1, 26, 47, 51, 42, 48, 13, 21, 35, 2, 32, 30, 41, 17, 3, 11, 9, 37, 25, 23, 46, 15, 50, 43, 36, 31, 52, 39, 0, 24, 28, 22, 33, 18, 29]\n",
      "===> Done training estimator # 8 in 202.70660614967346 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with features [52, 21, 14, 4, 44, 13, 38, 7, 35, 54, 1, 10, 15, 53, 49, 45, 19, 41, 56, 40, 0, 48, 26, 6, 18, 11, 55, 5, 31, 37, 34, 17, 27, 43, 51, 50, 20, 39, 42, 33, 23, 3, 8, 29, 9, 25, 28, 30, 47, 32, 36, 22, 12, 24, 2, 16, 46]\n",
      "===> Done training estimator # 9 in 196.4240918159485 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with features [22, 4, 5, 39, 2, 24, 40, 10, 49, 54, 35, 20, 42, 1, 27, 32, 18, 8, 36, 12, 46, 14, 16, 52, 48, 41, 55, 3, 19, 44, 56, 38, 21, 13, 28, 7, 53, 29, 6, 23, 33, 45, 17, 9, 26, 43, 25, 31, 0, 34, 37, 51, 30, 11, 15, 50, 47]\n",
      "===> Done training estimator # 10 in 197.53009033203125 seconds\n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "classfierData() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c6571cadf19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_est\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassfierData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: classfierData() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=57)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[670 403]\n",
      " [ 27  51]] \n",
      "\n",
      "True negative: 670 , false positive: 403 , false negative: 27 ,true positive: 51 \n",
      "\n",
      "Accuracy score 0.6264118158123371 \n",
      "\n",
      "Precision 0.11233480176211454 \n",
      "\n",
      "Recall 0.6538461538461539 \n",
      "\n",
      "F1 score 0.19172932330827067 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training estimator # 1 with features [15, 11, 16, 24, 13, 41, 7, 27, 55, 53, 37, 56, 18, 49, 10, 43, 30, 25, 17, 50, 6, 40, 12, 33, 0, 20, 39, 21]\n",
      "===> Done training estimator # 1 in 91.5327980518341 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with features [43, 42, 5, 14, 6, 55, 25, 20, 0, 24, 29, 46, 8, 36, 48, 34, 31, 49, 33, 1, 38, 12, 7, 50, 52, 53, 56, 3]\n",
      "===> Done training estimator # 2 in 83.30659604072571 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with features [44, 3, 2, 47, 15, 12, 11, 25, 33, 20, 19, 39, 50, 22, 45, 7, 27, 14, 42, 38, 41, 26, 52, 36, 4, 46, 24, 29]\n",
      "===> Done training estimator # 3 in 71.90655469894409 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with features [24, 51, 4, 3, 38, 12, 26, 54, 17, 56, 0, 28, 20, 55, 31, 30, 7, 14, 9, 47, 32, 49, 23, 29, 22, 25, 21, 40]\n",
      "===> Done training estimator # 4 in 116.64745092391968 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with features [48, 9, 38, 36, 16, 24, 5, 26, 22, 15, 35, 31, 42, 49, 34, 28, 50, 33, 46, 41, 39, 13, 6, 14, 44, 3, 54, 17]\n",
      "===> Done training estimator # 5 in 94.2670111656189 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with features [1, 8, 17, 30, 21, 13, 2, 4, 53, 22, 5, 47, 36, 38, 23, 0, 3, 37, 7, 43, 56, 24, 34, 39, 45, 32, 19, 15]\n",
      "===> Done training estimator # 6 in 79.00468873977661 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with features [23, 20, 52, 27, 37, 43, 46, 18, 45, 26, 54, 31, 51, 14, 30, 13, 25, 8, 6, 53, 12, 44, 38, 15, 32, 56, 2, 55]\n",
      "===> Done training estimator # 7 in 130.82872128486633 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with features [19, 8, 12, 56, 42, 22, 10, 5, 20, 30, 54, 50, 11, 51, 46, 48, 40, 34, 36, 27, 28, 33, 1, 35, 21, 44, 7, 43]\n",
      "===> Done training estimator # 8 in 92.25519490242004 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with features [22, 56, 39, 49, 16, 28, 13, 32, 0, 2, 55, 52, 41, 24, 51, 37, 4, 3, 36, 38, 43, 46, 47, 21, 6, 11, 40, 27]\n",
      "===> Done training estimator # 9 in 114.82949352264404 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with features [50, 44, 33, 28, 37, 35, 7, 18, 27, 41, 43, 45, 32, 3, 34, 36, 17, 22, 12, 15, 49, 55, 20, 16, 47, 1, 54, 56]\n",
      "===> Done training estimator # 10 in 102.75511479377747 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 11 with features [50, 2, 24, 14, 23, 21, 35, 20, 0, 46, 54, 6, 3, 48, 17, 52, 13, 43, 29, 37, 15, 34, 36, 27, 55, 11, 10, 7]\n",
      "===> Done training estimator # 11 in 110.86643171310425 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 12 with features [45, 23, 37, 51, 36, 18, 53, 2, 11, 24, 50, 16, 55, 46, 9, 0, 20, 8, 48, 10, 4, 41, 25, 47, 43, 38, 28, 29]\n",
      "===> Done training estimator # 12 in 92.21417880058289 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 13 with features [40, 12, 24, 13, 51, 22, 18, 36, 26, 9, 35, 45, 41, 53, 4, 52, 6, 11, 20, 0, 19, 3, 25, 46, 2, 48, 37, 7]\n",
      "===> Done training estimator # 13 in 123.64409685134888 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 14 with features [21, 11, 37, 48, 52, 2, 20, 23, 53, 43, 56, 0, 14, 4, 25, 29, 46, 7, 41, 9, 51, 22, 15, 19, 33, 8, 49, 54]\n",
      "===> Done training estimator # 14 in 136.35884714126587 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 15 with features [50, 8, 27, 9, 25, 45, 38, 10, 44, 12, 48, 23, 24, 30, 5, 3, 7, 17, 55, 28, 31, 4, 18, 33, 29, 43, 41, 34]\n",
      "===> Done training estimator # 15 in 84.06162619590759 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 16 with features [20, 5, 55, 43, 29, 6, 47, 27, 17, 12, 53, 38, 32, 3, 4, 2, 41, 39, 13, 54, 44, 24, 40, 30, 34, 23, 19, 22]\n",
      "===> Done training estimator # 16 in 110.12075662612915 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 17 with features [2, 12, 30, 13, 44, 5, 20, 21, 15, 33, 24, 41, 42, 54, 52, 19, 31, 36, 16, 18, 39, 43, 45, 55, 46, 28, 23, 51]\n",
      "===> Done training estimator # 17 in 128.85526871681213 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 18 with features [18, 40, 48, 22, 14, 35, 46, 7, 36, 20, 33, 25, 17, 28, 16, 53, 34, 12, 4, 38, 50, 3, 10, 1, 15, 39, 49, 44]\n",
      "===> Done training estimator # 18 in 85.14823484420776 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 19 with features [34, 46, 28, 29, 47, 23, 30, 19, 4, 43, 15, 27, 2, 53, 17, 7, 42, 6, 38, 16, 55, 21, 48, 35, 41, 24, 44, 52]\n",
      "===> Done training estimator # 19 in 101.35337829589844 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 20 with features [47, 50, 43, 32, 48, 18, 52, 30, 5, 9, 6, 16, 3, 14, 40, 1, 10, 15, 24, 34, 44, 49, 11, 7, 20, 33, 23, 22]\n",
      "===> Done training estimator # 20 in 113.41447687149048 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[203 160]\n",
      " [494 294]] \n",
      "\n",
      "True negative: 203 , false positive: 160 , false negative: 494 ,true positive: 294 \n",
      "\n",
      "Accuracy score 0.4317984361424848 \n",
      "\n",
      "Precision 0.6475770925110133 \n",
      "\n",
      "Recall 0.3730964467005076 \n",
      "\n",
      "F1 score 0.47342995169082125 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## With d/2 features\n",
    "rfc = RandomForestClassifier(num_est=20, max_depth=10, num_attrs=int(57/2))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with $\\sqrt{d}$ attributes and varying number of estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training estimator # 1 with features [11, 54, 3, 2, 35, 55, 15]\n",
      "===> Done training estimator # 1 in 26.35715341567993 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with features [39, 50, 16, 46, 1, 2, 4]\n",
      "===> Done training estimator # 2 in 13.443044662475586 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with features [19, 22, 8, 31, 7, 16, 43]\n",
      "===> Done training estimator # 3 in 13.193948745727539 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with features [14, 33, 22, 35, 39, 44, 54]\n",
      "===> Done training estimator # 4 in 29.668092966079712 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with features [34, 20, 8, 32, 4, 9, 48]\n",
      "===> Done training estimator # 5 in 17.91074538230896 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with features [38, 45, 11, 30, 56, 20, 43]\n",
      "===> Done training estimator # 6 in 23.102665901184082 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with features [32, 42, 12, 11, 27, 20, 13]\n",
      "===> Done training estimator # 7 in 20.540613174438477 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with features [27, 55, 35, 31, 6, 25, 42]\n",
      "===> Done training estimator # 8 in 18.703611373901367 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with features [54, 11, 28, 56, 18, 21, 45]\n",
      "===> Done training estimator # 9 in 31.72216296195984 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with features [19, 15, 12, 33, 34, 35, 9]\n",
      "===> Done training estimator # 10 in 10.867578029632568 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[384 202]\n",
      " [313 252]] \n",
      "\n",
      "True negative: 384 , false positive: 202 , false negative: 313 ,true positive: 252 \n",
      "\n",
      "Accuracy score 0.5525629887054735 \n",
      "\n",
      "Precision 0.5550660792951542 \n",
      "\n",
      "Recall 0.44601769911504424 \n",
      "\n",
      "F1 score 0.4946025515210991 \n",
      "\n",
      "*****************************************************************************************\n",
      "\n",
      "=== Training estimator # 1 with features [26, 12, 50, 48, 31, 46, 5]\n",
      "===> Done training estimator # 1 in 8.2955002784729 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with features [2, 34, 30, 32, 29, 1, 10]\n",
      "===> Done training estimator # 2 in 10.257475852966309 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with features [22, 39, 25, 43, 20, 19, 21]\n",
      "===> Done training estimator # 3 in 10.918535470962524 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with features [52, 18, 15, 33, 9, 40, 30]\n",
      "===> Done training estimator # 4 in 17.144760131835938 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with features [47, 11, 30, 39, 6, 29, 28]\n",
      "===> Done training estimator # 5 in 10.130049228668213 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with features [37, 3, 47, 1, 10, 2, 36]\n",
      "===> Done training estimator # 6 in 8.284183740615845 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with features [6, 1, 49, 32, 43, 31, 27]\n",
      "===> Done training estimator # 7 in 18.22270393371582 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with features [4, 35, 27, 15, 50, 52, 33]\n",
      "===> Done training estimator # 8 in 17.145228147506714 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with features [22, 2, 30, 14, 0, 20, 38]\n",
      "===> Done training estimator # 9 in 13.08021354675293 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with features [33, 44, 25, 21, 9, 7, 16]\n",
      "===> Done training estimator # 10 in 11.794970273971558 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 11 with features [40, 24, 53, 37, 7, 46, 51]\n",
      "===> Done training estimator # 11 in 14.392102718353271 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 12 with features [28, 49, 20, 53, 17, 27, 54]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-28b685d8f0f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_est\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mclassfierData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-5aeffd6beb68>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Training estimator #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===> Done training estimator #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"in\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_inst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDecTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDecTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindBestSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLeaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mfindBestSplit\u001b[0;34m(self, X, y, pp)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-339d15572878>\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(X, y, pred)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mfalse_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mfalse_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=20, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)\n",
    "\n",
    "print(\"*****************************************************************************************\\n\")\n",
    "\n",
    "rfc = RandomForestClassifier(num_est=50, max_depth=20, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)\n",
    "\n",
    "print(\"*****************************************************************************************\\n\")\n",
    "\n",
    "rfc = RandomForestClassifier(num_est=100, max_depth=20, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[626  30]\n",
      " [ 71 424]] \n",
      "\n",
      "True negative: 626 , false positive: 30 , false negative: 71 ,true positive: 424 \n",
      "\n",
      "Accuracy score 0.9122502172024327 \n",
      "\n",
      "Precision 0.933920704845815 \n",
      "\n",
      "Recall 0.8565656565656565 \n",
      "\n",
      "F1 score 0.8935721812434142 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=1, max_features=7)\n",
    "rfc.fit(X_test, y_test)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10), n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[675  44]\n",
      " [ 22 410]] \n",
      "\n",
      "True negative: 675 , false positive: 44 , false negative: 22 ,true positive: 410 \n",
      "\n",
      "Accuracy score 0.9426585577758471 \n",
      "\n",
      "Precision 0.9030837004405287 \n",
      "\n",
      "Recall 0.9490740740740741 \n",
      "\n",
      "F1 score 0.9255079006772009 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(ada, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ada = AdaBoostClassifier(LogisticRegression(), n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[656  63]\n",
      " [ 41 391]] \n",
      "\n",
      "True negative: 656 , false positive: 63 , false negative: 41 ,true positive: 391 \n",
      "\n",
      "Accuracy score 0.9096437880104257 \n",
      "\n",
      "Precision 0.8612334801762115 \n",
      "\n",
      "Recall 0.9050925925925926 \n",
      "\n",
      "F1 score 0.8826185101580134 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada.fit(X_train, y_train)\n",
    "classfierData(ada, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost classifier data for 10 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[667  40]\n",
      " [ 30 414]] \n",
      "\n",
      "True negative: 667 , false positive: 40 , false negative: 30 ,true positive: 414 \n",
      "\n",
      "Accuracy score 0.9391833188531712 \n",
      "\n",
      "Precision 0.9118942731277533 \n",
      "\n",
      "Recall 0.9324324324324325 \n",
      "\n",
      "F1 score 0.9220489977728284 \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "AdaBoost classifier data for 50 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[674  37]\n",
      " [ 23 417]] \n",
      "\n",
      "True negative: 674 , false positive: 37 , false negative: 23 ,true positive: 417 \n",
      "\n",
      "Accuracy score 0.947871416159861 \n",
      "\n",
      "Precision 0.9185022026431718 \n",
      "\n",
      "Recall 0.9477272727272728 \n",
      "\n",
      "F1 score 0.9328859060402686 \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "AdaBoost classifier data for 100 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[672  35]\n",
      " [ 25 419]] \n",
      "\n",
      "True negative: 672 , false positive: 35 , false negative: 25 ,true positive: 419 \n",
      "\n",
      "Accuracy score 0.947871416159861 \n",
      "\n",
      "Precision 0.9229074889867841 \n",
      "\n",
      "Recall 0.9436936936936937 \n",
      "\n",
      "F1 score 0.9331848552338531 \n",
      "\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_learners = [10, 50, 100]\n",
    "# use with decision tree\n",
    "for l in base_learners:\n",
    "    ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10), n_estimators=l)\n",
    "    ada.fit(X_train, y_train)\n",
    "    print(\"AdaBoost classifier data for\", l, \"number of estimators\\n\")\n",
    "    print(\"*********************************************************************\")\n",
    "    classfierData(ada, X_test, y_test)\n",
    "    print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost classifier data for 10 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[681  32]\n",
      " [ 16 422]] \n",
      "\n",
      "True negative: 681 , false positive: 32 , false negative: 16 ,true positive: 422 \n",
      "\n",
      "Accuracy score 0.9582971329278888 \n",
      "\n",
      "Precision 0.9295154185022027 \n",
      "\n",
      "Recall 0.9634703196347032 \n",
      "\n",
      "F1 score 0.946188340807175 \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "AdaBoost classifier data for 50 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[680  38]\n",
      " [ 17 416]] \n",
      "\n",
      "True negative: 680 , false positive: 38 , false negative: 17 ,true positive: 416 \n",
      "\n",
      "Accuracy score 0.952215464813206 \n",
      "\n",
      "Precision 0.9162995594713657 \n",
      "\n",
      "Recall 0.9607390300230947 \n",
      "\n",
      "F1 score 0.9379932356257047 \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "AdaBoost classifier data for 100 number of estimators\n",
      "\n",
      "*********************************************************************\n",
      "Confusion matrix\n",
      " [[686  43]\n",
      " [ 11 411]] \n",
      "\n",
      "True negative: 686 , false positive: 43 , false negative: 11 ,true positive: 411 \n",
      "\n",
      "Accuracy score 0.9530842745438749 \n",
      "\n",
      "Precision 0.9052863436123348 \n",
      "\n",
      "Recall 0.9739336492890995 \n",
      "\n",
      "F1 score 0.9383561643835616 \n",
      "\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for l in base_learners:\n",
    "    ada = AdaBoostClassifier(RandomForestClassifier(n_estimators=10), n_estimators=l)\n",
    "    ada.fit(X_train, y_train)\n",
    "    print(\"AdaBoost classifier data for\", l, \"number of estimators\\n\")\n",
    "    print(\"*********************************************************************\")\n",
    "    classfierData(ada, X_test, y_test)\n",
    "    print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "X_train = np.reshape(X_train, (60000, 784))\n",
    "X_test = np.reshape(X_test, (10000, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for FFN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will have 3 hidden layer. Each layer (except for the last one to produce result) will use relu as activation functions. After calculating neurons for each layer, Dropout Regularization will be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=28*28))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "rms = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(model, epochs=20, batch=256):\n",
    "    start_time = time.time()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
    "    print('Training model...')\n",
    "    model.fit(X_train, y_train, nb_epoch=epochs, batch_size=batch,\n",
    "              validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    print(\"Training duration : {0}\".format(time.time() - start_time))\n",
    "    score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "    print(\"Network's test score [loss, accuracy]: {0}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 0.0345 - acc: 0.9898 - val_loss: 0.0791 - val_acc: 0.9831\n",
      "Epoch 2/20\n",
      " - 4s - loss: 0.0316 - acc: 0.9907 - val_loss: 0.0790 - val_acc: 0.9833\n",
      "Epoch 3/20\n",
      " - 4s - loss: 0.0280 - acc: 0.9916 - val_loss: 0.0838 - val_acc: 0.9821\n",
      "Epoch 4/20\n",
      " - 4s - loss: 0.0279 - acc: 0.9918 - val_loss: 0.0903 - val_acc: 0.9828\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.0290 - acc: 0.9914 - val_loss: 0.0767 - val_acc: 0.9845\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.0282 - acc: 0.9920 - val_loss: 0.0801 - val_acc: 0.9838\n",
      "Epoch 7/20\n",
      " - 4s - loss: 0.0266 - acc: 0.9925 - val_loss: 0.0878 - val_acc: 0.9835\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.0260 - acc: 0.9921 - val_loss: 0.0905 - val_acc: 0.9838\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.0269 - acc: 0.9929 - val_loss: 0.0920 - val_acc: 0.9841\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.0257 - acc: 0.9924 - val_loss: 0.0863 - val_acc: 0.9850\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.0236 - acc: 0.9932 - val_loss: 0.1030 - val_acc: 0.9821\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.0241 - acc: 0.9935 - val_loss: 0.0922 - val_acc: 0.9824\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.0252 - acc: 0.9929 - val_loss: 0.0993 - val_acc: 0.9840\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.0230 - acc: 0.9935 - val_loss: 0.0951 - val_acc: 0.9848\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.0242 - acc: 0.9935 - val_loss: 0.1009 - val_acc: 0.9842\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.0231 - acc: 0.9936 - val_loss: 0.0964 - val_acc: 0.9835\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.0234 - acc: 0.9940 - val_loss: 0.0892 - val_acc: 0.9845\n",
      "Epoch 18/20\n",
      " - 4s - loss: 0.0215 - acc: 0.9936 - val_loss: 0.0910 - val_acc: 0.9827\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.0226 - acc: 0.9936 - val_loss: 0.0970 - val_acc: 0.9830\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.0221 - acc: 0.9939 - val_loss: 0.0913 - val_acc: 0.9845\n",
      "Training duration : 88.50944209098816\n",
      "10000/10000 [==============================] - 1s 103us/step\n",
      "Network's test score [loss, accuracy]: [0.091294884948584, 0.9845]\n"
     ]
    }
   ],
   "source": [
    "run_network(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=28*28))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.7692 - acc: 0.8160 - val_loss: 0.3984 - val_acc: 0.8976\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.3676 - acc: 0.8992 - val_loss: 0.3253 - val_acc: 0.9091\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.3219 - acc: 0.9103 - val_loss: 0.2997 - val_acc: 0.9168\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.3025 - acc: 0.9153 - val_loss: 0.2912 - val_acc: 0.9183\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.2912 - acc: 0.9188 - val_loss: 0.2834 - val_acc: 0.9217\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2837 - acc: 0.9206 - val_loss: 0.2768 - val_acc: 0.9230\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.2780 - acc: 0.9224 - val_loss: 0.2734 - val_acc: 0.9246\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.2737 - acc: 0.9240 - val_loss: 0.2718 - val_acc: 0.9244\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.2701 - acc: 0.9251 - val_loss: 0.2694 - val_acc: 0.9251\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.2673 - acc: 0.9257 - val_loss: 0.2704 - val_acc: 0.9253\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.2651 - acc: 0.9257 - val_loss: 0.2663 - val_acc: 0.9253\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2628 - acc: 0.9273 - val_loss: 0.2660 - val_acc: 0.9259\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2611 - acc: 0.9278 - val_loss: 0.2662 - val_acc: 0.9263\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2594 - acc: 0.9282 - val_loss: 0.2681 - val_acc: 0.9257\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2580 - acc: 0.9287 - val_loss: 0.2641 - val_acc: 0.9271\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2566 - acc: 0.9292 - val_loss: 0.2660 - val_acc: 0.9273\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2554 - acc: 0.9297 - val_loss: 0.2648 - val_acc: 0.9269\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2542 - acc: 0.9301 - val_loss: 0.2649 - val_acc: 0.9272\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2533 - acc: 0.9301 - val_loss: 0.2663 - val_acc: 0.9272\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2524 - acc: 0.9309 - val_loss: 0.2643 - val_acc: 0.9278\n",
      "Training duration : 10.083073616027832\n",
      "10000/10000 [==============================] - 0s 24us/step\n",
      "Network's test score [loss, accuracy]: [0.2643152913760394, 0.9278]\n"
     ]
    }
   ],
   "source": [
    "run_network(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=28*28))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 0.3396 - acc: 0.9065 - val_loss: 0.1913 - val_acc: 0.9442\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.1540 - acc: 0.9558 - val_loss: 0.1285 - val_acc: 0.9628\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.1070 - acc: 0.9691 - val_loss: 0.1071 - val_acc: 0.9664\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.0800 - acc: 0.9764 - val_loss: 0.0836 - val_acc: 0.9754\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.0625 - acc: 0.9811 - val_loss: 0.0739 - val_acc: 0.9775\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.0507 - acc: 0.9848 - val_loss: 0.0720 - val_acc: 0.9787\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.0409 - acc: 0.9881 - val_loss: 0.0689 - val_acc: 0.9794\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.0333 - acc: 0.9904 - val_loss: 0.0704 - val_acc: 0.9791\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.0272 - acc: 0.9928 - val_loss: 0.0670 - val_acc: 0.9802\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.0226 - acc: 0.9939 - val_loss: 0.0694 - val_acc: 0.9798\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0182 - acc: 0.9953 - val_loss: 0.0710 - val_acc: 0.9798\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0150 - acc: 0.9963 - val_loss: 0.0623 - val_acc: 0.9818\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0121 - acc: 0.9972 - val_loss: 0.0687 - val_acc: 0.9798\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0685 - val_acc: 0.9804\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0082 - acc: 0.9983 - val_loss: 0.0698 - val_acc: 0.9810\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0066 - acc: 0.9986 - val_loss: 0.0751 - val_acc: 0.9800\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0704 - val_acc: 0.9816\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0043 - acc: 0.9992 - val_loss: 0.0726 - val_acc: 0.9812\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0039 - acc: 0.9993 - val_loss: 0.0800 - val_acc: 0.9803\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0793 - val_acc: 0.9810\n",
      "Training duration : 38.59053421020508\n",
      "10000/10000 [==============================] - 1s 58us/step\n",
      "Network's test score [loss, accuracy]: [0.07925795914844659, 0.981]\n"
     ]
    }
   ],
   "source": [
    "run_network(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Neural network, we will not flatten the $28 \\times 28$ image into a $781 \\times 1$ vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "convMod = Sequential()\n",
    "\n",
    "convMod.add(Conv2D(64, (2, 2), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "convMod.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "convMod.add(Conv2D(64, (2, 2), activation = 'relu'))\n",
    "convMod.add(MaxPooling2D(pool_size = (1, 1)))\n",
    "convMod.add(Dropout(0.2))\n",
    "\n",
    "convMod.add(Flatten())\n",
    "\n",
    "convMod.add(Dense(units = 128, activation='relu'))\n",
    "convMod.add(Dropout(0.5))\n",
    "convMod.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 4704/60000 [=>............................] - ETA: 1:17 - loss: 0.1121 - acc: 0.9722"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-d34a88c45f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconvMod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconvMod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convMod.compile(optimizer=rms, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "convMod.fit(x_train, y_train,epochs=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 344us/step\n",
      "[0.06280644375819575, 0.982]\n"
     ]
    }
   ],
   "source": [
    "print(convMod.evaluate(x_test, y_test, batch_size=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "convMod = Sequential()\n",
    "\n",
    "convMod.add(Conv2D(64, (4, 4), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "convMod.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "convMod.add(Dropout(0.2))\n",
    "convMod.add(Flatten())\n",
    "convMod.add(Dense(units = 128, activation='relu'))\n",
    "convMod.add(Dropout(0.5))\n",
    "convMod.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.2170 - acc: 0.9356\n",
      "Epoch 2/10\n",
      "  704/60000 [..............................] - ETA: 1:18 - loss: 0.0899 - acc: 0.9702"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-d34a88c45f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconvMod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconvMod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/school/4400/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convMod.compile(optimizer=rms, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "convMod.fit(x_train, y_train,epochs=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "convMod = Sequential()\n",
    "\n",
    "convMod.add(Conv2D(64, (2, 2), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "convMod.add(MaxPooling2D(pool_size = (1, 1)))\n",
    "convMod.add(Dropout(0.4))\n",
    "convMod.add(Flatten())\n",
    "convMod.add(Dense(units = 32, activation='relu'))\n",
    "convMod.add(Dropout(0.8))\n",
    "convMod.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.6712 - acc: 0.7834\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 125s 2ms/step - loss: 0.4398 - acc: 0.8685\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 134s 2ms/step - loss: 0.4140 - acc: 0.8766\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.4362 - acc: 0.8731\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 133s 2ms/step - loss: 0.4357 - acc: 0.8737\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 135s 2ms/step - loss: 0.4422 - acc: 0.8720\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.4417 - acc: 0.8721\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.4455 - acc: 0.8721\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.4485 - acc: 0.8717\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.4534 - acc: 0.8698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb7710fe80>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convMod.compile(optimizer=rms, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "convMod.fit(x_train, y_train,epochs=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 333us/step\n",
      "[0.1301682964519132, 0.9654]\n"
     ]
    }
   ],
   "source": [
    "print(convMod.evaluate(x_test, y_test, batch_size=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
