{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "matrix = []\n",
    "\n",
    "with open(\"spambase.data\", \"r\") as raw_data:\n",
    "    for raw_line in raw_data:\n",
    "        line = [float(x) for x in raw_line.split(\",\")]\n",
    "        matrix.append(line)\n",
    "\n",
    "data = pd.DataFrame(matrix)\n",
    "row, col = data.shape\n",
    "X, y = data.iloc[:,:col - 1], data[col - 1]\n",
    "# y = y.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest Classifier on existing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfierData(clf, X, y):\n",
    "    test_data = clf.predict(X)\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(test_data, y), \"\\n\")\n",
    "    tn, fp, fn, tp = confusion_matrix(test_data, y).ravel()\n",
    "    print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "    print(\"Accuracy score\", accuracy_score(test_data, y), \"\\n\")\n",
    "    print(\"Precision\", precision_score(test_data, y), \"\\n\")\n",
    "    print(\"Recall\", recall_score(test_data, y), \"\\n\")\n",
    "    print(\"F1 score\", f1_score(test_data, y), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[2089    1]\n",
      " [   2 1358]] \n",
      "\n",
      "True negative: 2089 , false positive: 1 , false negative: 2 ,true positive: 1358 \n",
      "\n",
      "Accuracy score 0.9991304347826087 \n",
      "\n",
      "Precision 0.9992641648270787 \n",
      "\n",
      "Recall 0.9985294117647059 \n",
      "\n",
      "F1 score 0.9988966531813166 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[681  46]\n",
      " [ 16 408]] \n",
      "\n",
      "True negative: 681 , false positive: 46 , false negative: 16 ,true positive: 408 \n",
      "\n",
      "Accuracy score 0.946133796698523 \n",
      "\n",
      "Precision 0.8986784140969163 \n",
      "\n",
      "Recall 0.9622641509433962 \n",
      "\n",
      "F1 score 0.9293849658314352 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing own Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicate class acts as the splitting question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    def match(self, example, pp=False):\n",
    "        if pp:\n",
    "            print(\"Match on column\", self.column)\n",
    "        val = example[self.column]\n",
    "        if Util.is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility functions that being reused a lot in the implementation of random forest. In this implementation, I used gini impurity instead of entropy since `log` function would arguably take longer to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Util:\n",
    "    @staticmethod\n",
    "    def label_count(labels):\n",
    "        count = {}\n",
    "        for r in labels:\n",
    "            if r not in count:\n",
    "                count[r] = 0\n",
    "            count[r] += 1\n",
    "        return count\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_numeric(val):\n",
    "        return isinstance(val, int) or isinstance(val, float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition(X, y, pred):\n",
    "        true_X, false_X, true_y, false_y = [], [], [], []\n",
    "        \n",
    "        for x_inst, y_inst in zip(X, y):\n",
    "            if pred.match(x_inst):\n",
    "                true_X.append(x_inst)\n",
    "                true_y.append(y_inst)\n",
    "            else:\n",
    "                false_X.append(x_inst)\n",
    "                false_y.append(y_inst)\n",
    "        return true_X, true_y, false_X, false_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_impur(labels):\n",
    "        \"\"\"\n",
    "        Gini impurity\n",
    "        \"\"\"\n",
    "        counts = Util.label_count(labels)\n",
    "        total = 0\n",
    "        for lbl in counts:\n",
    "            prob_of_lbl = float(counts[lbl]) / len(labels)\n",
    "            total += (prob_of_lbl * prob_of_lbl)\n",
    "        return 1 - total\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_gain(leftLbl, rightLbl, curr_uncertainty):\n",
    "        \"\"\"\n",
    "        Calculating information gain\n",
    "        \"\"\"\n",
    "        p = float (len(leftLbl)) / (len(leftLbl) + len(rightLbl))\n",
    "        return curr_uncertainty - p * Util.gini_impur(leftLbl) - (1 - p) * Util.gini_impur(rightLbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, y, depth=0):\n",
    "        self.depth = depth\n",
    "        pred = Util.label_count(y)\n",
    "        for l in pred:\n",
    "            pred[l] = pred[l] / len(y)\n",
    "        self.predictions = pred\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return True\n",
    "\n",
    "class DecTreeNode:\n",
    "    def __init__(self, pred, true_branch, false_branch, depth=0):\n",
    "        self.depth = depth\n",
    "        self.pred = pred\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecTreeClassifier:\n",
    "    def __init__(self, max_depth=10):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def findBestSplit(self, X, y, pp=False):\n",
    "        start = time.time()\n",
    "        best_gain = 0  \n",
    "        best_pred = None\n",
    "        current_uncert = Util.gini_impur(y)\n",
    "        \n",
    "        for col in self.selected_features:\n",
    "            vals = set([row[col] for row in X]) # different values in column\n",
    "            \n",
    "            for v in vals:\n",
    "                pred = Predicate(col, v)\n",
    "                true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "                \n",
    "                if len(true_X) == 0 or len(false_X) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = Util.info_gain(true_y, false_y, current_uncert)\n",
    "                \n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_pred = gain, pred\n",
    "        if pp:\n",
    "            print(\"Find best split size\", np.array(X).shape, \"took\", time.time() - start)\n",
    "        return best_gain, best_pred\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        gain, pred = self.findBestSplit(X, y)\n",
    "        if gain == 0 or depth >= self.max_depth:\n",
    "            return Leaf(y, depth)\n",
    "        true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "        \n",
    "        true_branch = self.build_tree(true_X, true_y, depth + 1)\n",
    "        false_branch = self.build_tree(false_X, false_y, depth + 1)\n",
    "        \n",
    "        return DecTreeNode(pred, true_branch, false_branch)\n",
    "    \n",
    "    def predict_by_tree(self, tree, X_inst):\n",
    "        if tree.isLeaf():\n",
    "            return tree.predictions\n",
    "        elif tree.pred.match(X_inst, pp=False):\n",
    "            return self.predict_by_tree(tree.true_branch, X_inst)\n",
    "        else:\n",
    "            return self.predict_by_tree(tree.false_branch, X_inst)\n",
    "    \n",
    "    def fit(self, X, y, selected_features=None):\n",
    "        if selected_features is None:\n",
    "            self.selected_features = X.columns\n",
    "        else:\n",
    "            self.selected_features = selected_features\n",
    "            \n",
    "        self.tree = self.build_tree(X.values, y.values) \n",
    "    \n",
    "    def predict_inst(self, X_inst):\n",
    "        pred = self.predict_by_tree(self.tree, np.array(X_inst))\n",
    "        max_arg, max_prob = None, 0\n",
    "        for l in pred:\n",
    "            if pred[l] > max_prob:\n",
    "                max_arg = l\n",
    "            max_prob = max(max_prob, pred[l])\n",
    "        return max_arg\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for idx, r in X.iterrows():\n",
    "            y.append(self.predict_inst(r))\n",
    "        return pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on columns RangeIndex(start=0, stop=57, step=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-a2b63a981400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdecTreeClf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdecTreeClf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decision tree classifier take\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds to build tree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-67f41d073545>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, selected_features)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_inst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-67f41d073545>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindBestSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLeaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-67f41d073545>\u001b[0m in \u001b[0;36mfindBestSplit\u001b[0;34m(self, X, y, pp)\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_uncert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbest_gain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-339d15572878>\u001b[0m in \u001b[0;36minfo_gain\u001b[0;34m(leftLbl, rightLbl, curr_uncertainty)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[1;32m     47\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftLbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftLbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrightLbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcurr_uncertainty\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgini_impur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftLbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgini_impur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrightLbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-339d15572878>\u001b[0m in \u001b[0;36mgini_impur\u001b[0;34m(labels)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mGini\u001b[0m \u001b[0mimpurity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-339d15572878>\u001b[0m in \u001b[0;36mlabel_count\u001b[0;34m(labels)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training decision tree\n",
    "decTreeClf = DecTreeClassifier(max_depth=10)\n",
    "start = time.time()\n",
    "decTreeClf.fit(X_train, y_train)\n",
    "print(\"Decision tree classifier take\", time.time() - start, \"seconds to build tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to build a full tree with depth 10, it took me 247 seconds (~4 minutes). Having max depth helps us limit the training time and also avoid overfitting on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[663  66]\n",
      " [ 34 388]] \n",
      "\n",
      "True negative: 663 , false positive: 66 , false negative: 34 ,true positive: 388 \n",
      "\n",
      "Accuracy score 0.9131190269331017 \n",
      "\n",
      "Precision 0.8546255506607929 \n",
      "\n",
      "Recall 0.919431279620853 \n",
      "\n",
      "F1 score 0.8858447488584474 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(decTreeClf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[665  63]\n",
      " [ 32 391]] \n",
      "\n",
      "True negative: 665 , false positive: 63 , false negative: 32 ,true positive: 391 \n",
      "\n",
      "Accuracy score 0.9174630755864466 \n",
      "\n",
      "Precision 0.8612334801762115 \n",
      "\n",
      "Recall 0.9243498817966903 \n",
      "\n",
      "F1 score 0.8916761687571265 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dcf = DecisionTreeClassifier(max_depth=10)\n",
    "dcf.fit(X_train, y_train)\n",
    "classfierData(dcf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, my implementation of Decision Tree Classifier gains approximately the same result as sklearn's Decision Tree Classifier. Now we can implement random forest classifier after decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import random\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, num_est=10, max_depth=5, num_attrs=5):\n",
    "        self.num_est = num_est\n",
    "        self.max_depth = max_depth\n",
    "        self.forest = []\n",
    "        self.num_attrs = num_attrs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Bagging\n",
    "        for i in range(self.num_est):\n",
    "            shape = len(X.columns)\n",
    "            \n",
    "            selected_features = random.sample(range(0, shape), self.num_attrs)\n",
    "            X_samp, y_samp = resample(X, y, replace=True, random_state=0)\n",
    "            print(\"Size of new sample\", X_samp.shape)\n",
    "            clf = DecTreeClassifier(max_depth=self.max_depth)\n",
    "            start = time.time()\n",
    "            print(\"=== Training estimator #\", i + 1, \"with\", len(selected_features),\"features\")\n",
    "            clf.fit(X_samp, y_samp, selected_features=selected_features)\n",
    "            print(\"===> Done training estimator #\", i + 1, \"in\", time.time() - start, \"seconds\")\n",
    "            self.forest.append(clf)\n",
    "            print(\"--------------------------------------------------------------\\n\")\n",
    "            \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for idx, x in X.iterrows():\n",
    "            labels = {}\n",
    "            for clf in self.forest:\n",
    "                l = clf.predict_inst(x)\n",
    "                if l not in labels:\n",
    "                    labels[l] = 0\n",
    "                labels[l] += 1\n",
    "            for l in labels:\n",
    "                if labels[l] >= 0.5:\n",
    "                    result.append(l)\n",
    "                    break\n",
    "        return pd.DataFrame(result)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing random forest on $\\sqrt{d}$ attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training estimator # 1 with 7 features\n",
      "===> Done training estimator # 1 in 33.332377910614014 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with 7 features\n",
      "===> Done training estimator # 2 in 26.17583441734314 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with 7 features\n",
      "===> Done training estimator # 3 in 16.308863162994385 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with 7 features\n",
      "===> Done training estimator # 4 in 33.756556272506714 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with 7 features\n",
      "===> Done training estimator # 5 in 8.893163442611694 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with 7 features\n",
      "===> Done training estimator # 6 in 17.65627884864807 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with 7 features\n",
      "===> Done training estimator # 7 in 12.278050422668457 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with 7 features\n",
      "===> Done training estimator # 8 in 21.560562133789062 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with 7 features\n",
      "===> Done training estimator # 9 in 11.31926417350769 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with 7 features\n",
      "===> Done training estimator # 10 in 21.553426027297974 seconds\n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[592 119]\n",
      " [105 335]] \n",
      "\n",
      "True negative: 592 , false positive: 119 , false negative: 105 ,true positive: 335 \n",
      "\n",
      "Accuracy score 0.8053866203301477 \n",
      "\n",
      "Precision 0.737885462555066 \n",
      "\n",
      "Recall 0.7613636363636364 \n",
      "\n",
      "F1 score 0.7494407158836689 \n",
      "\n",
      "Confusion matrix\n",
      " [[1905  251]\n",
      " [ 186 1108]] \n",
      "\n",
      "True negative: 1905 , false positive: 251 , false negative: 186 ,true positive: 1108 \n",
      "\n",
      "Accuracy score 0.8733333333333333 \n",
      "\n",
      "Precision 0.8153053715967623 \n",
      "\n",
      "Recall 0.8562596599690881 \n",
      "\n",
      "F1 score 0.8352808141726347 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(rfc, X_test, y_test)\n",
    "classfierData(rfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest on all attributes with 10 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training estimator # 1 with features [36, 11, 9, 12, 35, 32, 37, 56, 43, 22, 53, 39, 23, 20, 51, 30, 52, 14, 49, 44, 1, 31, 34, 10, 28, 8, 26, 40, 41, 2, 29, 18, 27, 50, 19, 45, 38, 25, 15, 16, 47, 3, 4, 46, 33, 6, 0, 17, 55, 7, 24, 21, 5, 42, 48, 54, 13]\n",
      "===> Done training estimator # 1 in 239.93970227241516 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with features [0, 15, 21, 48, 20, 4, 46, 33, 18, 54, 31, 8, 1, 36, 5, 16, 52, 11, 39, 26, 25, 40, 53, 41, 55, 10, 3, 32, 43, 27, 38, 45, 6, 49, 28, 22, 47, 2, 37, 50, 42, 12, 14, 30, 56, 23, 9, 7, 35, 13, 17, 29, 44, 24, 19, 34, 51]\n",
      "===> Done training estimator # 2 in 247.90983271598816 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with features [46, 23, 48, 8, 55, 10, 56, 16, 4, 2, 9, 36, 5, 28, 26, 54, 20, 39, 11, 18, 51, 30, 41, 13, 17, 19, 22, 29, 49, 35, 1, 45, 3, 42, 38, 32, 7, 12, 33, 37, 34, 53, 52, 15, 0, 21, 31, 24, 14, 50, 27, 43, 47, 6, 40, 25, 44]\n",
      "===> Done training estimator # 3 in 211.30190110206604 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with features [6, 48, 22, 54, 18, 39, 23, 19, 32, 45, 53, 27, 43, 37, 36, 0, 12, 20, 29, 52, 47, 13, 9, 33, 5, 56, 16, 40, 49, 42, 44, 4, 34, 10, 14, 3, 38, 1, 7, 50, 15, 11, 24, 28, 55, 30, 51, 41, 35, 26, 17, 31, 21, 8, 46, 25, 2]\n",
      "===> Done training estimator # 4 in 199.1002550125122 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with features [16, 7, 12, 54, 23, 0, 49, 27, 6, 9, 52, 33, 13, 45, 22, 26, 5, 34, 46, 37, 38, 40, 2, 15, 1, 44, 53, 8, 17, 56, 47, 25, 28, 35, 10, 31, 50, 51, 3, 48, 41, 21, 36, 55, 18, 11, 39, 20, 19, 43, 24, 30, 4, 32, 29, 42, 14]\n",
      "===> Done training estimator # 5 in 196.6109220981598 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with features [10, 55, 28, 9, 29, 3, 31, 14, 39, 32, 24, 27, 47, 50, 48, 46, 1, 15, 49, 26, 37, 43, 22, 25, 18, 19, 4, 45, 5, 56, 16, 21, 41, 8, 42, 11, 54, 20, 0, 35, 38, 33, 51, 44, 12, 40, 7, 34, 17, 30, 6, 52, 36, 53, 23, 13, 2]\n",
      "===> Done training estimator # 6 in 196.98835849761963 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with features [27, 47, 51, 17, 38, 0, 56, 36, 49, 44, 46, 13, 28, 42, 55, 5, 29, 20, 41, 12, 35, 8, 33, 21, 6, 15, 22, 3, 53, 34, 43, 11, 39, 26, 16, 10, 14, 30, 2, 9, 52, 31, 40, 37, 4, 32, 45, 54, 48, 23, 18, 19, 25, 24, 7, 1, 50]\n",
      "===> Done training estimator # 7 in 198.19417262077332 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with features [19, 12, 16, 6, 38, 40, 49, 8, 14, 4, 55, 27, 45, 54, 56, 10, 34, 5, 7, 20, 44, 53, 1, 26, 47, 51, 42, 48, 13, 21, 35, 2, 32, 30, 41, 17, 3, 11, 9, 37, 25, 23, 46, 15, 50, 43, 36, 31, 52, 39, 0, 24, 28, 22, 33, 18, 29]\n",
      "===> Done training estimator # 8 in 202.70660614967346 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with features [52, 21, 14, 4, 44, 13, 38, 7, 35, 54, 1, 10, 15, 53, 49, 45, 19, 41, 56, 40, 0, 48, 26, 6, 18, 11, 55, 5, 31, 37, 34, 17, 27, 43, 51, 50, 20, 39, 42, 33, 23, 3, 8, 29, 9, 25, 28, 30, 47, 32, 36, 22, 12, 24, 2, 16, 46]\n",
      "===> Done training estimator # 9 in 196.4240918159485 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with features [22, 4, 5, 39, 2, 24, 40, 10, 49, 54, 35, 20, 42, 1, 27, 32, 18, 8, 36, 12, 46, 14, 16, 52, 48, 41, 55, 3, 19, 44, 56, 38, 21, 13, 28, 7, 53, 29, 6, 23, 33, 45, 17, 9, 26, 43, 25, 31, 0, 34, 37, 51, 30, 11, 15, 50, 47]\n",
      "===> Done training estimator # 10 in 197.53009033203125 seconds\n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "classfierData() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c6571cadf19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_est\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassfierData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: classfierData() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=10, num_attrs=57)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[670 403]\n",
      " [ 27  51]] \n",
      "\n",
      "True negative: 670 , false positive: 403 , false negative: 27 ,true positive: 51 \n",
      "\n",
      "Accuracy score 0.6264118158123371 \n",
      "\n",
      "Precision 0.11233480176211454 \n",
      "\n",
      "Recall 0.6538461538461539 \n",
      "\n",
      "F1 score 0.19172932330827067 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training estimator # 1 with features [15, 11, 16, 24, 13, 41, 7, 27, 55, 53, 37, 56, 18, 49, 10, 43, 30, 25, 17, 50, 6, 40, 12, 33, 0, 20, 39, 21]\n",
      "===> Done training estimator # 1 in 91.5327980518341 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with features [43, 42, 5, 14, 6, 55, 25, 20, 0, 24, 29, 46, 8, 36, 48, 34, 31, 49, 33, 1, 38, 12, 7, 50, 52, 53, 56, 3]\n",
      "===> Done training estimator # 2 in 83.30659604072571 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with features [44, 3, 2, 47, 15, 12, 11, 25, 33, 20, 19, 39, 50, 22, 45, 7, 27, 14, 42, 38, 41, 26, 52, 36, 4, 46, 24, 29]\n",
      "===> Done training estimator # 3 in 71.90655469894409 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with features [24, 51, 4, 3, 38, 12, 26, 54, 17, 56, 0, 28, 20, 55, 31, 30, 7, 14, 9, 47, 32, 49, 23, 29, 22, 25, 21, 40]\n",
      "===> Done training estimator # 4 in 116.64745092391968 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with features [48, 9, 38, 36, 16, 24, 5, 26, 22, 15, 35, 31, 42, 49, 34, 28, 50, 33, 46, 41, 39, 13, 6, 14, 44, 3, 54, 17]\n",
      "===> Done training estimator # 5 in 94.2670111656189 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with features [1, 8, 17, 30, 21, 13, 2, 4, 53, 22, 5, 47, 36, 38, 23, 0, 3, 37, 7, 43, 56, 24, 34, 39, 45, 32, 19, 15]\n",
      "===> Done training estimator # 6 in 79.00468873977661 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with features [23, 20, 52, 27, 37, 43, 46, 18, 45, 26, 54, 31, 51, 14, 30, 13, 25, 8, 6, 53, 12, 44, 38, 15, 32, 56, 2, 55]\n",
      "===> Done training estimator # 7 in 130.82872128486633 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with features [19, 8, 12, 56, 42, 22, 10, 5, 20, 30, 54, 50, 11, 51, 46, 48, 40, 34, 36, 27, 28, 33, 1, 35, 21, 44, 7, 43]\n",
      "===> Done training estimator # 8 in 92.25519490242004 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with features [22, 56, 39, 49, 16, 28, 13, 32, 0, 2, 55, 52, 41, 24, 51, 37, 4, 3, 36, 38, 43, 46, 47, 21, 6, 11, 40, 27]\n",
      "===> Done training estimator # 9 in 114.82949352264404 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with features [50, 44, 33, 28, 37, 35, 7, 18, 27, 41, 43, 45, 32, 3, 34, 36, 17, 22, 12, 15, 49, 55, 20, 16, 47, 1, 54, 56]\n",
      "===> Done training estimator # 10 in 102.75511479377747 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 11 with features [50, 2, 24, 14, 23, 21, 35, 20, 0, 46, 54, 6, 3, 48, 17, 52, 13, 43, 29, 37, 15, 34, 36, 27, 55, 11, 10, 7]\n",
      "===> Done training estimator # 11 in 110.86643171310425 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 12 with features [45, 23, 37, 51, 36, 18, 53, 2, 11, 24, 50, 16, 55, 46, 9, 0, 20, 8, 48, 10, 4, 41, 25, 47, 43, 38, 28, 29]\n",
      "===> Done training estimator # 12 in 92.21417880058289 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 13 with features [40, 12, 24, 13, 51, 22, 18, 36, 26, 9, 35, 45, 41, 53, 4, 52, 6, 11, 20, 0, 19, 3, 25, 46, 2, 48, 37, 7]\n",
      "===> Done training estimator # 13 in 123.64409685134888 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 14 with features [21, 11, 37, 48, 52, 2, 20, 23, 53, 43, 56, 0, 14, 4, 25, 29, 46, 7, 41, 9, 51, 22, 15, 19, 33, 8, 49, 54]\n",
      "===> Done training estimator # 14 in 136.35884714126587 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 15 with features [50, 8, 27, 9, 25, 45, 38, 10, 44, 12, 48, 23, 24, 30, 5, 3, 7, 17, 55, 28, 31, 4, 18, 33, 29, 43, 41, 34]\n",
      "===> Done training estimator # 15 in 84.06162619590759 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 16 with features [20, 5, 55, 43, 29, 6, 47, 27, 17, 12, 53, 38, 32, 3, 4, 2, 41, 39, 13, 54, 44, 24, 40, 30, 34, 23, 19, 22]\n",
      "===> Done training estimator # 16 in 110.12075662612915 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 17 with features [2, 12, 30, 13, 44, 5, 20, 21, 15, 33, 24, 41, 42, 54, 52, 19, 31, 36, 16, 18, 39, 43, 45, 55, 46, 28, 23, 51]\n",
      "===> Done training estimator # 17 in 128.85526871681213 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 18 with features [18, 40, 48, 22, 14, 35, 46, 7, 36, 20, 33, 25, 17, 28, 16, 53, 34, 12, 4, 38, 50, 3, 10, 1, 15, 39, 49, 44]\n",
      "===> Done training estimator # 18 in 85.14823484420776 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 19 with features [34, 46, 28, 29, 47, 23, 30, 19, 4, 43, 15, 27, 2, 53, 17, 7, 42, 6, 38, 16, 55, 21, 48, 35, 41, 24, 44, 52]\n",
      "===> Done training estimator # 19 in 101.35337829589844 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 20 with features [47, 50, 43, 32, 48, 18, 52, 30, 5, 9, 6, 16, 3, 14, 40, 1, 10, 15, 24, 34, 44, 49, 11, 7, 20, 33, 23, 22]\n",
      "===> Done training estimator # 20 in 113.41447687149048 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[203 160]\n",
      " [494 294]] \n",
      "\n",
      "True negative: 203 , false positive: 160 , false negative: 494 ,true positive: 294 \n",
      "\n",
      "Accuracy score 0.4317984361424848 \n",
      "\n",
      "Precision 0.6475770925110133 \n",
      "\n",
      "Recall 0.3730964467005076 \n",
      "\n",
      "F1 score 0.47342995169082125 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## With d/2 features\n",
    "rfc = RandomForestClassifier(num_est=20, max_depth=10, num_attrs=int(57/2))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with $\\sqrt{d}$ attributes and varying number of estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training estimator # 1 with features [11, 54, 3, 2, 35, 55, 15]\n",
      "===> Done training estimator # 1 in 26.35715341567993 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with features [39, 50, 16, 46, 1, 2, 4]\n",
      "===> Done training estimator # 2 in 13.443044662475586 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with features [19, 22, 8, 31, 7, 16, 43]\n",
      "===> Done training estimator # 3 in 13.193948745727539 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with features [14, 33, 22, 35, 39, 44, 54]\n",
      "===> Done training estimator # 4 in 29.668092966079712 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with features [34, 20, 8, 32, 4, 9, 48]\n",
      "===> Done training estimator # 5 in 17.91074538230896 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with features [38, 45, 11, 30, 56, 20, 43]\n",
      "===> Done training estimator # 6 in 23.102665901184082 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with features [32, 42, 12, 11, 27, 20, 13]\n",
      "===> Done training estimator # 7 in 20.540613174438477 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with features [27, 55, 35, 31, 6, 25, 42]\n",
      "===> Done training estimator # 8 in 18.703611373901367 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with features [54, 11, 28, 56, 18, 21, 45]\n",
      "===> Done training estimator # 9 in 31.72216296195984 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with features [19, 15, 12, 33, 34, 35, 9]\n",
      "===> Done training estimator # 10 in 10.867578029632568 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Confusion matrix\n",
      " [[384 202]\n",
      " [313 252]] \n",
      "\n",
      "True negative: 384 , false positive: 202 , false negative: 313 ,true positive: 252 \n",
      "\n",
      "Accuracy score 0.5525629887054735 \n",
      "\n",
      "Precision 0.5550660792951542 \n",
      "\n",
      "Recall 0.44601769911504424 \n",
      "\n",
      "F1 score 0.4946025515210991 \n",
      "\n",
      "*****************************************************************************************\n",
      "\n",
      "=== Training estimator # 1 with features [26, 12, 50, 48, 31, 46, 5]\n",
      "===> Done training estimator # 1 in 8.2955002784729 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 2 with features [2, 34, 30, 32, 29, 1, 10]\n",
      "===> Done training estimator # 2 in 10.257475852966309 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 3 with features [22, 39, 25, 43, 20, 19, 21]\n",
      "===> Done training estimator # 3 in 10.918535470962524 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 4 with features [52, 18, 15, 33, 9, 40, 30]\n",
      "===> Done training estimator # 4 in 17.144760131835938 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 5 with features [47, 11, 30, 39, 6, 29, 28]\n",
      "===> Done training estimator # 5 in 10.130049228668213 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 6 with features [37, 3, 47, 1, 10, 2, 36]\n",
      "===> Done training estimator # 6 in 8.284183740615845 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 7 with features [6, 1, 49, 32, 43, 31, 27]\n",
      "===> Done training estimator # 7 in 18.22270393371582 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 8 with features [4, 35, 27, 15, 50, 52, 33]\n",
      "===> Done training estimator # 8 in 17.145228147506714 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 9 with features [22, 2, 30, 14, 0, 20, 38]\n",
      "===> Done training estimator # 9 in 13.08021354675293 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 10 with features [33, 44, 25, 21, 9, 7, 16]\n",
      "===> Done training estimator # 10 in 11.794970273971558 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 11 with features [40, 24, 53, 37, 7, 46, 51]\n",
      "===> Done training estimator # 11 in 14.392102718353271 seconds\n",
      "--------------------------------------------------------------\n",
      "\n",
      "=== Training estimator # 12 with features [28, 49, 20, 53, 17, 27, 54]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-28b685d8f0f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_est\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mclassfierData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-5aeffd6beb68>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Training estimator #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===> Done training estimator #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"in\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_inst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDecTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtrue_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mfalse_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDecTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_branch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_branch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindBestSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLeaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ebe121cb00c>\u001b[0m in \u001b[0;36mfindBestSplit\u001b[0;34m(self, X, y, pp)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-339d15572878>\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(X, y, pred)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mfalse_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mfalse_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(num_est=10, max_depth=20, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)\n",
    "\n",
    "print(\"*****************************************************************************************\\n\")\n",
    "\n",
    "rfc = RandomForestClassifier(num_est=50, max_depth=20, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)\n",
    "\n",
    "print(\"*****************************************************************************************\\n\")\n",
    "\n",
    "rfc = RandomForestClassifier(num_est=100, max_depth=20, num_attrs=int(np.sqrt(57)))\n",
    "rfc.fit(X_train, y_train)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[626  30]\n",
      " [ 71 424]] \n",
      "\n",
      "True negative: 626 , false positive: 30 , false negative: 71 ,true positive: 424 \n",
      "\n",
      "Accuracy score 0.9122502172024327 \n",
      "\n",
      "Precision 0.933920704845815 \n",
      "\n",
      "Recall 0.8565656565656565 \n",
      "\n",
      "F1 score 0.8935721812434142 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=1, max_features=7)\n",
    "rfc.fit(X_test, y_test)\n",
    "classfierData(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
