{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "matrix = []\n",
    "\n",
    "with open(\"spambase.data\", \"r\") as raw_data:\n",
    "    for raw_line in raw_data:\n",
    "        line = [float(x) for x in raw_line.split(\",\")]\n",
    "        matrix.append(line)\n",
    "\n",
    "data = pd.DataFrame(matrix)\n",
    "row, col = data.shape\n",
    "X, y = data.iloc[:,:col - 1], data[col - 1]\n",
    "# y = y.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4 , 0.6 ],\n",
       "       [0.97, 0.03],\n",
       "       [0.96, 0.04],\n",
       "       ...,\n",
       "       [1.  , 0.  ],\n",
       "       [0.91, 0.09],\n",
       "       [0.58, 0.42]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[677  40]\n",
      " [ 20 414]] \n",
      "\n",
      "True negative: 677 , false positive: 40 , false negative: 20 ,true positive: 414 \n",
      "\n",
      "Accuracy score 0.947871416159861 \n",
      "\n",
      "Precision 0.9118942731277533 \n",
      "\n",
      "Recall 0.9539170506912442 \n",
      "\n",
      "F1 score 0.9324324324324325 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = clf.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(test_data, y_test), \"\\n\")\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_data, y_test).ravel()\n",
    "print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "\n",
    "print(\"Accuracy score\", accuracy_score(test_data, y_test), \"\\n\")\n",
    "\n",
    "print(\"Precision\", precision_score(test_data, y_test), \"\\n\")\n",
    "\n",
    "print(\"Recall\", recall_score(test_data, y_test), \"\\n\")\n",
    "\n",
    "print(\"F1 score\", f1_score(test_data, y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[2091    0]\n",
      " [   0 1359]] \n",
      "\n",
      "True negative: 2091 , false positive: 0 , false negative: 0 ,true positive: 1359 \n",
      "\n",
      "Accuracy score 1.0 \n",
      "\n",
      "Precision 1.0 \n",
      "\n",
      "Recall 1.0 \n",
      "\n",
      "F1 score 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = clf.predict(X_train)\n",
    "\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(test_data, y_train), \"\\n\")\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_data, y_train).ravel()\n",
    "print(\"True negative:\", tn, \", false positive:\", fp, \", false negative:\", fn, \",true positive:\", tp, \"\\n\")\n",
    "\n",
    "print(\"Accuracy score\", accuracy_score(test_data, y_train), \"\\n\")\n",
    "\n",
    "print(\"Precision\", precision_score(test_data, y_train), \"\\n\")\n",
    "\n",
    "print(\"Recall\", recall_score(test_data, y_train), \"\\n\")\n",
    "\n",
    "print(\"F1 score\", f1_score(test_data, y_train), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    \n",
    "    def match(self, example):\n",
    "        if self.column in example:\n",
    "            val = example[self.column]\n",
    "            if Util.is_numeric(val):\n",
    "                return val >= self.value\n",
    "            else:\n",
    "                return val == self.value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if Util.is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header[self.column], condition, str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement decision tree classifier for numerical feature\n",
    "\n",
    "class Util:\n",
    "    @staticmethod\n",
    "    def label_count(labels):\n",
    "        count = {}\n",
    "        for r in labels:\n",
    "            if r not in count:\n",
    "                count[r] = 0\n",
    "            count[r] += 1\n",
    "        return count\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_numeric(val):\n",
    "        return isinstance(val, int) or isinstance(val, float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition(X, y, pred):\n",
    "        true_X, false_X, true_y, false_y = [], [], [], []\n",
    "        \n",
    "        for x_inst, y_inst  in zip(X, y):\n",
    "            if pred.match(x_inst):\n",
    "                true_X.append(x_inst)\n",
    "                true_y.append(y_inst)\n",
    "            else:\n",
    "                false_X.append(x_inst)\n",
    "                false_y.append(y_inst)\n",
    "        return true_X, true_y, false_X, false_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_impur(labels):\n",
    "        \"\"\"\n",
    "        Gini impurity\n",
    "        \"\"\"\n",
    "        counts = Util.label_count(labels)\n",
    "        total = 0\n",
    "        for lbl in counts:\n",
    "            prob_of_lbl = float(counts[lbl]) / len(labels)\n",
    "            total += (prob_of_lbl * prob_of_lbl)\n",
    "        return 1 - total\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_gain(leftLbl, rightLbl, curr_uncertainty):\n",
    "        \"\"\"\n",
    "        Calculating information gain\n",
    "        \"\"\"\n",
    "        p = float (len(leftLbl)) / (len(leftLbl) + len(rightLbl))\n",
    "        return curr_uncertainty - p * Util.gini_impur(leftLbl) - (1 - p) * Util.gini_impur(rightLbl)\n",
    "        \n",
    "class Leaf:\n",
    "    def __init__(self, y):\n",
    "        pred = Util.label_count(y)\n",
    "        for l in pred:\n",
    "            pred[l] = pred[l] / len(y)\n",
    "        self.predictions = pred\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return True\n",
    "\n",
    "class DecTreeNode:\n",
    "    def __init__(self, pred, true_branch, false_branch):\n",
    "        self.pred = pred\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return False\n",
    "    \n",
    "class DecTreeClassifier:\n",
    "    def __init__(self, max_depth=10):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def findBestSplit(self, X, y):\n",
    "        best_gain = 0  \n",
    "        best_pred = None\n",
    "        current_uncert = Util.gini_impur(y)\n",
    "        n_features = np.array(X).shape[1]\n",
    "        \n",
    "        for col in range(n_features):\n",
    "            vals = set([row[col] for row in X]) # different values in column\n",
    "            \n",
    "            for v in vals:\n",
    "                pred = Predicate(col, v)\n",
    "                true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "                \n",
    "                if len(true_X) == 0 or len(false_X) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = Util.info_gain(true_y, false_y, current_uncert)\n",
    "                \n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_pred = gain, pred\n",
    "        return best_gain, best_pred\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        gain, pred = self.findBestSplit(X, y)\n",
    "        if gain == 0 or depth == self.max_depth:\n",
    "            return Leaf(y)\n",
    "        true_X, true_y, false_X, false_y = Util.partition(X, y, pred)\n",
    "        \n",
    "        true_branch = self.build_tree(true_X, true_y, depth + 1)\n",
    "        false_branch = self.build_tree(false_X, false_y, depth + 1)\n",
    "        \n",
    "        return DecTreeNode(pred, true_branch, false_branch)\n",
    "    \n",
    "    def predict_by_tree(self, tree, X_inst):\n",
    "        if tree.isLeaf():\n",
    "            return tree.predictions\n",
    "        elif tree.pred.match(X_inst):\n",
    "            return self.predict_by_tree(tree.true_branch, X_inst)\n",
    "        else:\n",
    "            return self.predict_by_tree(tree.false_branch, X_inst)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(X.values, y.values) \n",
    "    \n",
    "    def predict_instance(self, X_inst):\n",
    "        return self.predict_by_tree(self.tree, X_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier take 217.1205952167511 seconds to build tree\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "decTreeClf = DecTreeClassifier()\n",
    "start = time.time()\n",
    "decTreeClf.fit(X_train[:1000], y_train[:1000])\n",
    "print(\"Decision tree classifier take\", time.time() - start, \"seconds to build tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.8823529411764706, 1.0: 0.11764705882352941}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decTreeClf.predict(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.8823529411764706, 1.0: 0.11764705882352941}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decTreeClf.predict(X_test[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, num_est=10):\n",
    "        self.num_est = num_est\n",
    "        self.forest = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Bagging\n",
    "        for i in range(self.num_est):\n",
    "            X_samp, y_samp = resample(X, y, replace=True, random_state=0)\n",
    "            clf = DecTreeClassifier()\n",
    "            clf.fit(X_samp, y_samp)\n",
    "            self.forest.append(clf)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        labels = {}\n",
    "        for clf in self.forest:\n",
    "            y = clf.predict(X)\n",
    "            if y not in labels:\n",
    "                labels[y] = 0\n",
    "            labels[y] += 1\n",
    "        \n",
    "        for l in labels:\n",
    "            labels[l] = labels[i] / self.num_est\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
